{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13efee6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d64868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-class-alzheimers\n",
      "\n",
      "Loaded the images of dataset-class-frontotemporal\n",
      "\n",
      "Loaded the images of dataset-class-healthy\n",
      "\n",
      "Class 0: 883 samples\n",
      "Class 1: 533 samples\n",
      "Class 2: 786 samples\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# data_path=\"./Final-dataset\"\n",
    "# data_dir_list = ['class-alzheimers', 'class-frontotemporal', 'class-healthy']\n",
    "# img_data_list=[]\n",
    "# labels = []\n",
    "# for dataset in data_dir_list:\n",
    "#     img_list=os.listdir(data_path+'/'+ dataset)\n",
    "#     print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "#     for img in img_list:\n",
    "#         if img[-3:] == 'jpg':\n",
    "#             input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "# #             input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "#             labels.append(dataset)\n",
    "#             input_img_resize=cv2.resize(input_img,(128, 128))\n",
    "#             img_data_list.append(input_img_resize)\n",
    "# label=np.array(labels)\n",
    "# img_data = np.array(img_data_list)\n",
    "# img_data = img_data.astype('float32')\n",
    "# img_data = img_data/255\n",
    "# img_data.shape\n",
    "\n",
    "\n",
    "#                        *********** Main code for final data laoding and training Starts here *********\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# data_path = \"./Final-dataset\"\n",
    "# data_dir_list = ['class-alzheimers', 'class-frontotemporal', 'class-healthy']\n",
    "# img_data_list = []\n",
    "# labels = []\n",
    "\n",
    "# for dataset in data_dir_list:\n",
    "#     img_list = os.listdir(os.path.join(data_path, dataset))\n",
    "#     print('Loaded the images of dataset-{}\\n'.format(dataset))\n",
    "#     for img in img_list:\n",
    "#         if img[-3:] == 'png':\n",
    "#             input_img = cv2.imread(os.path.join(data_path, dataset, img))\n",
    "#             # Convert the image to grayscale if needed\n",
    "#             # input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "#             labels.append(dataset)\n",
    "#             input_img_resize = cv2.resize(input_img, (126, 126))  # update the pixel size (if needed)\n",
    "#             img_data_list.append(input_img_resize)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(labels)\n",
    "# label = label_encoder.transform(labels)\n",
    "\n",
    "# img_data = np.array(img_data_list).astype('float32') / 255\n",
    "\n",
    "# # Calculate sample count for each class\n",
    "# class_counts = np.bincount(label)\n",
    "\n",
    "# # Display the sample count for each class\n",
    "# for i, count in enumerate(class_counts):\n",
    "#     print(f\"Class {i}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b08f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/dtypes.py:597: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat.v2'; 'tensorflow.compat' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/__internal__/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/__internal__/backend/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/applications/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/applications/convnext.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mReferences:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m  (CVPR 2022)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat.v2'; 'tensorflow.compat' is not a package"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_classes = 3\n",
    "Y = to_categorical(label, num_classes)\n",
    "x, y = shuffle(img_data, Y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a81acfc1",
   "metadata": {},
   "source": [
    "plt.imshow(img_data_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc5509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 128, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 128, 128, 3)\n",
    "X_test = X_test.reshape(-1, 128, 128, 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57668cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 256 295168      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 256 1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 256)    0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 256)    0           global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 32)     8224        reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 256)    8448        dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 1, 256)    0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1, 1, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 128, 128, 256 0           batch_normalization_3[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 1)  12545       multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 256 0           multiply[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 32) 73760       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 128, 128, 32) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 32) 9248        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 32) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 32) 8224        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           re_lu_1[0][0]                    \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 131072)       0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 524288)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 688128)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          352322048   concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            258         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 352,997,315\n",
      "Trainable params: 352,996,355\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dropout, Activation, Multiply, Input, Add, Flatten, GlobalMaxPooling2D, Dense, Reshape, BatchNormalization, GlobalAveragePooling2D, Permute\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def cbam_attention(inputs, reduction_ratio=8):\n",
    "    # Channel attention\n",
    "    x = inputs\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
    "    channel = x.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel // reduction_ratio, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')\n",
    "    shared_layer_two = Dense(channel, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), use_bias=True)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(x)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(x)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "        \n",
    "    attention_feature = Multiply()([x, cbam_feature])\n",
    "\n",
    "    # Spatial attention\n",
    "    kernel_size = 7\n",
    "    spatial_attention = Conv2D(1, (kernel_size, kernel_size), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), padding='same')(attention_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        spatial_attention = Permute((3, 1, 2))(spatial_attention)\n",
    "\n",
    "    attention_feature = Multiply()([attention_feature, spatial_attention])\n",
    "\n",
    "    return attention_feature\n",
    "\n",
    "def residual_block(input_layer, filters, kernel_size):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # Add a 1x1 convolutional layer to adjust the number of channels\n",
    "    adjust_channels = layers.Conv2D(filters, (1, 1), padding='same')(input_layer)\n",
    "    x = Add()([x, adjust_channels])\n",
    "    return x\n",
    "\n",
    "# Explicitly name the input layer\n",
    "visible = Input(shape=(128, 128, 3))\n",
    "\n",
    "ds_1 = Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(visible)\n",
    "x1 = BatchNormalization()(ds_1)\n",
    "ds_2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x1)\n",
    "x2 = BatchNormalization()(ds_2)\n",
    "ds_3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x2)\n",
    "x3 = BatchNormalization()(ds_3)\n",
    "ds_4 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x3)\n",
    "x4 = BatchNormalization()(ds_4)\n",
    "# ds_5 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(ds_4)\n",
    "c = cbam_attention(x4, 8)\n",
    "\n",
    "# Residual block 1\n",
    "x = residual_block(c, filters=32, kernel_size=(3, 3))\n",
    "\n",
    "\n",
    "#replace global average pulling \n",
    "# Spatial Pyramid Pooling (SPP)\n",
    "# pool_sizes = [4, 2, 1] \n",
    "# spp_layers = []\n",
    "# for pool_size in pool_sizes:\n",
    "#     spp = layers.MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n",
    "#     spp = layers.Flatten()(spp)\n",
    "#     spp_layers.append(spp)\n",
    "\n",
    "# spp = layers.Concatenate()(spp_layers)\n",
    "# x = layers.Dense(512, activation='relu')(spp)\n",
    "# x1 = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Fully Connected Layers\n",
    "x10 = Dense(256, activation='relu')(x1)\n",
    "x10 = Dense(128, activation='relu')(x10)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = Dense(2, activation='softmax')(x10)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=visible, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e460e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=30,\n",
    "    min_delta=0.001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint_directory =  '/workspace/All/Osteoporosis knee/Code/Checkpoints'\n",
    "epoch= 200\n",
    "checkpoint = ModelCheckpoint(\n",
    "   checkpoint_directory + f'Epoch1_{epoch}.h5', \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da3076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples, validate on 123 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 04:58:00.700759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-02-12 04:58:00.721348: E tensorflow/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-12 04:58:00.721374: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2024-02-12 04:58:00.770212: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2245750000 Hz\n",
      "2024-02-12 04:58:00.793766: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb43dcc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-12 04:58:00.793828: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "480/492 [============================>.] - ETA: 4s - loss: 112.5952 - acc: 0.5708 \n",
      "Epoch 00001: val_acc improved from -inf to 0.50407, saving model to /workspace/All/Osteoporosis knee/Code/CheckpointsEpoch1_200.h5\n",
      "492/492 [==============================] - 211s 429ms/sample - loss: 110.3021 - acc: 0.5711 - val_loss: 16.4841 - val_acc: 0.5041\n",
      "Epoch 2/200\n",
      "336/492 [===================>..........] - ETA: 1:02 - loss: 20.5488 - acc: 0.6399"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "     X_train,\n",
    "     y_train,\n",
    "     epochs=200,\n",
    "     batch_size=16,\n",
    "     validation_data=(X_test, y_test),\n",
    "     callbacks=[checkpoint],\n",
    "     verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Multiply, Input, Add, Flatten, GlobalMaxPooling2D, Dense, Reshape, GlobalAveragePooling2D, Permute, Concatenate\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def cbam_attention(inputs, reduction_ratio=8):\n",
    "    # Channel attention\n",
    "    x = inputs\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
    "    channel = x.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel // reduction_ratio, kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')\n",
    "    shared_layer_two = Dense(channel, kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), use_bias=True)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(x)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(x)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    attention_feature = Multiply()([x, cbam_feature])\n",
    "\n",
    "    # Spatial attention\n",
    "    kernel_size = 7\n",
    "    spatial_attention = Conv2D(1, (kernel_size, kernel_size), kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), padding='same')(attention_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        spatial_attention = Permute((3, 1, 2))(spatial_attention)\n",
    "\n",
    "    attention_feature = Multiply()([attention_feature, spatial_attention])\n",
    "\n",
    "    return attention_feature\n",
    "\n",
    "def residual_block(input_layer, filters, kernel_size):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # Add a 1x1 convolutional layer to adjust the number of channels\n",
    "    adjust_channels = layers.Conv2D(filters, (1, 1), padding='same')(input_layer)\n",
    "    x = Add()([x, adjust_channels])\n",
    "    return x\n",
    "\n",
    "# Explicitly name the input layer\n",
    "visible = Input(shape=(128, 128, 3), name='input_image')\n",
    "x1 = Conv2D(128, (3, 3), dilation_rate=1, padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')(visible)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x2 = Conv2D(128, (3, 3), dilation_rate=3, padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')(x1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x3 = Conv2D(128, (3, 3), dilation_rate=5, padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')(x2)\n",
    "x3 = BatchNormalization()(x3)\n",
    "\n",
    "A1 = Add()([x1, x2])\n",
    "M1 = Multiply()([x2, x3])\n",
    "\n",
    "x4 = Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')(A1)\n",
    "x4 = BatchNormalization()(x4)\n",
    "g1 = GlobalAveragePooling2D()(x4)\n",
    "d1 = Dense(1, activation='sigmoid')(g1)\n",
    "M3 = Multiply()([d1, x1])\n",
    "\n",
    "x5 = Activation('softmax')(M1)\n",
    "M2 = Multiply()([x3, x5])\n",
    "\n",
    "# Concatenate layers\n",
    "C1 = Concatenate()([M2, M3])\n",
    "x5 = Conv2D(256, (3, 3), padding = 'same', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), activation='relu')(C1)\n",
    "C2 = Concatenate()([x5, visible])\n",
    "x = cbam_attention(C2)\n",
    "x = Add()([x, C2])\n",
    "# Residual block 1\n",
    "r = residual_block(x, filters=64, kernel_size=(3, 3))\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(r)\n",
    "x1 = layers.Dropout(0.25)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e781941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=15,\n",
    "    min_delta=0.001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint_directory =  '/workspace/All/Osteoporosis knee/Code/Checkpoints'\n",
    "epoch= 200\n",
    "checkpoint = ModelCheckpoint(\n",
    "   checkpoint_directory + f'Epoch1_{epoch}.h5', \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f657cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "     X_train,\n",
    "     y_train,\n",
    "     epochs=200,\n",
    "     batch_size=16,\n",
    "     validation_data=(X_test, y_test),\n",
    "     callbacks=[checkpoint, early_stopping],\n",
    "     verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d9f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
