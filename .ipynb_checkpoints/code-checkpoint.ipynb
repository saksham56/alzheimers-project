{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375eb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Loading the dataset for extracting the spectograms from it \n",
    "# import numpy as np \n",
    "# import pandas as pd \n",
    "# import os\n",
    "\n",
    "# for dirname, _, filenames in os.walk('./dataset-2'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aea53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #                      Code to create epoch data from the dataset\n",
    "# import mne\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Create a directory to store the data if it doesn't exist\n",
    "# output_folder = 'epochs_data'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # Read subject information\n",
    "# subjects_info = pd.read_csv('./dataset-2/participants.tsv', delimiter='\\t')\n",
    "\n",
    "# # Create an empty DataFrame to store epochs information\n",
    "# epochs_info_df = pd.DataFrame(columns=['participant_id', 'epoch_index'])\n",
    "\n",
    "# for i in range(1, 89):\n",
    "#     # Load EEG data\n",
    "#     file_path = f'./dataset-2/sub-{i:03}/eeg/sub-{i:03}_task-eyesclosed_eeg.set'\n",
    "#     raw_data = mne.io.read_raw_eeglab(file_path,preload=True)\n",
    "\n",
    "#     # Extract subject information from subjects_info DataFrame\n",
    "#     subject_info = subjects_info[subjects_info['participant_id'] == f'sub-{i:03}'].iloc[0]\n",
    "\n",
    "#     # Create epochs\n",
    "#     epochs = mne.make_fixed_length_epochs(raw_data, duration=45, proj=True, overlap=15)\n",
    "#     epochs_data = epochs.get_data()\n",
    "\n",
    "#     # Save epochs data\n",
    "#     np.save(os.path.join(output_folder, f'subject_{i}.npy'), epochs_data)\n",
    "    \n",
    "#     n=epochs_data.shape[1]\n",
    "#     row_to_duplicate =subjects_info.iloc[i-1]\n",
    "#     duplicated_rows = pd.DataFrame([row_to_duplicate] * n, columns=subjects_info.columns)\n",
    "#     duplicated_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     # Save the duplicated rows to a file\n",
    "#     duplicated_rows.to_csv(os.path.join(output_folder,(f'epochs_information_sub_{i}.csv')), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cf492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(subject_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b67615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Source folders\n",
    "# epochs_folder = 'epochs_data'  # Folder containing EEG data files\n",
    "# json_folder = 'dataset-2'  # Folder containing JSON files\n",
    "\n",
    "# # Destination folder\n",
    "# destination_folder = 'subject_spectrograms_with_json'  # Folder where organized data will be moved\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# if not os.path.exists(destination_folder):\n",
    "#     os.makedirs(destination_folder)\n",
    "\n",
    "# # Iterate through subjects (assuming subjects are numbered from 1 to 88)\n",
    "# for subject_id in range(1, 89):\n",
    "#     # Construct subject ID string with leading zeros\n",
    "#     subject_id_str = f'sub-{subject_id:03}'\n",
    "\n",
    "#     # Find the EEG file for the subject\n",
    "#     eeg_file = f'subject_{subject_id:03}.npy'\n",
    "#     eeg_source_path = os.path.join(epochs_folder, eeg_file)\n",
    "\n",
    "#     # Find the JSON file for the subject\n",
    "#     json_file = f'subject_{subject_id:03}.json'\n",
    "#     json_source_path = os.path.join(json_folder, subject_id_str, 'eeg', json_file)\n",
    "\n",
    "#     # Create a folder for the subject in the destination folder\n",
    "#     subject_folder = os.path.join(destination_folder, subject_id_str)\n",
    "#     os.makedirs(subject_folder, exist_ok=True)\n",
    "\n",
    "#     # Move the JSON file to the subject folder\n",
    "#     if os.path.exists(json_source_path):\n",
    "#         shutil.copy(json_source_path, subject_folder)\n",
    "\n",
    "#     # Generate spectrogram for the EEG data\n",
    "#     if os.path.exists(eeg_source_path):\n",
    "#         eeg_data = np.load(eeg_source_path)  # Load EEG data\n",
    "#         sampling_rate = 1000  # Sample rate in Hz\n",
    "\n",
    "#         # Assuming EEG data is in the first column of the DataFrame and each row corresponds to an epoch\n",
    "#         for epoch_index in range(len(eeg_data)):\n",
    "#             epoch_eeg_data = eeg_data[epoch_index]\n",
    "#             save_path = os.path.join(destination_folder, f'spectrogram_{subject_id:03}_epoch_{epoch_index}.png')\n",
    "#             plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ff4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Source folders\n",
    "# epochs_folder = 'epochs_data'  # Folder containing EEG data files\n",
    "# json_folder = 'dataset-2'  # Folder containing JSON files\n",
    "\n",
    "# # Destination folder\n",
    "# destination_folder = 'subject_spectrograms_with_json'  # Folder where organized data will be moved\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# if not os.path.exists(destination_folder):\n",
    "#     os.makedirs(destination_folder)\n",
    "\n",
    "# # Iterate through subjects (assuming subjects are numbered from 1 to 88)\n",
    "# for subject_id in range(1, 89):\n",
    "#     # Construct subject ID string with leading zeros\n",
    "#     subject_id_str = f'sub-{subject_id:03}'\n",
    "\n",
    "#     # Find the EEG file for the subject\n",
    "#     eeg_file = f'subject_{subject_id:03}.npy'\n",
    "#     eeg_source_path = os.path.join(epochs_folder, eeg_file)\n",
    "\n",
    "#     # Find the JSON file for the subject\n",
    "#     json_file = f'subject_{subject_id:03}.json'\n",
    "#     json_source_path = os.path.join(json_folder, subject_id_str, 'eeg', json_file)\n",
    "\n",
    "#     # Create a folder for the subject in the destination folder\n",
    "#     subject_folder = os.path.join(destination_folder, subject_id_str)\n",
    "#     os.makedirs(subject_folder, exist_ok=True)\n",
    "    \n",
    "    \n",
    "#     csv_files = [file for file in os.listdir(epochs_folder) if file.endswith('.csv')]\n",
    "#     # Generate spectrogram for the EEG data and move JSON file\n",
    "#     if os.path.exists(eeg_source_path):\n",
    "#         # Load EEG data (assuming it's in the form of a numpy array)\n",
    "#         for csv_file in csv_files:\n",
    "#             csv_path = os.path.join(folder_path, csv_file)\n",
    "#             participant_data = pd.read_csv(csv_path)\n",
    "#             eeg_data = np.load(os.path.join(folder_path, f'subject_{csv_file.split(\"_\")[3].split(\".\")[0]}.npy'))  # Load EEG data (replace with your actual file naming convention)\n",
    "#             sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is in the first column of the DataFrame and each row corresponds to an epoch\n",
    "#             for epoch_index in range(len(eeg_data)):\n",
    "#                 epoch_eeg_data = eeg_data[epoch_index]\n",
    "#                 save_path = os.path.join(spectrogram_folder, f'spectrogram_{csv_file.split(\"_\")[3].split(\".\")[0]}_epoch_{epoch_index}.png')\n",
    "#                 plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "            \n",
    "#     # Move the JSON file to the subject folder\n",
    "#     if os.path.exists(json_source_path):\n",
    "#         shutil.copy(json_source_path, subject_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6362900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #       Code for converting the csv and nmpy files into spectograms in png format \n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis', NFFT=256)\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')a\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Read all CSV files into a single DataFrame\n",
    "# folder_path = 'epochs_data'\n",
    "# csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# # Create a directory to store spectrogram images if it doesn't exist\n",
    "# spectrogram_folder = 'spectrograms'\n",
    "# if not os.path.exists(spectrogram_folder):\n",
    "#     os.makedirs(spectrogram_folder)\n",
    "\n",
    "# for csv_file in csv_files:\n",
    "#     csv_path = os.path.join(folder_path, csv_file)\n",
    "#     participant_data = pd.read_csv(csv_path)\n",
    "#     participant_id = csv_file.split(\"_\")[3].split(\".\")[0]\n",
    "#     participant_folder = os.path.join(spectrogram_folder, f'sub-{participant_id}')\n",
    "#     if not os.path.exists(participant_folder):\n",
    "#         os.makedirs(participant_folder)\n",
    "        \n",
    "#     eeg_data_path = os.path.join(folder_path, f'subject_{participant_id}.npy')  # Assuming EEG data path\n",
    "#     eeg_data = np.load(eeg_data_path)  # Load EEG data\n",
    "#     sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is a 2D array where each row corresponds to an epoch\n",
    "#     for epoch_index, epoch_eeg_data in enumerate(eeg_data):\n",
    "#         save_path = os.path.join(participant_folder, f'spectrogram_epoch_{epoch_index}.png')\n",
    "#         plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6f8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis', NFFT=256)\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Read all CSV files into a single DataFrame\n",
    "# folder_path = 'epochs_data'\n",
    "# csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# # Create a directory to store spectrogram images if it doesn't exist\n",
    "# spectrogram_folder = 'spectrograms'\n",
    "# if not os.path.exists(spectrogram_folder):\n",
    "#     os.makedirs(spectrogram_folder)\n",
    "\n",
    "# for csv_file in csv_files:\n",
    "#     csv_path = os.path.join(folder_path, csv_file)\n",
    "#     participant_data = pd.read_csv(csv_path)\n",
    "#     participant_id = csv_file.split(\"_\")[3].split(\".\")[0]\n",
    "#     participant_folder = os.path.join(spectrogram_folder, f'sub-{participant_id}')\n",
    "#     if not os.path.exists(participant_folder):\n",
    "#         os.makedirs(participant_folder)\n",
    "        \n",
    "#     eeg_data_path = os.path.join(folder_path, f'subject_{participant_id}.npy')  # Assuming EEG data path\n",
    "#     eeg_data = np.load(eeg_data_path)  # Load EEG data\n",
    "#     sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is a 2D array where each row corresponds to an epoch\n",
    "#     for epoch_index, epoch_eeg_data in enumerate(eeg_data):\n",
    "#         save_path = os.path.join(participant_folder, f'spectrogram_epoch_{epoch_index}.png')\n",
    "#         plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "    \n",
    "#     # Move the JSON file to the participant folder\n",
    "#         json_source_path = os.path.join('dataset-2', f'sub-{participant_id}', 'eeg', f'sub-{participant_id}_task-eyesclosed_channels.tsv')\n",
    "#         json_destination_path = os.path.join(participant_folder, f'subject_{participant_id}.tsv')\n",
    "#         if os.path.exists(json_source_path):\n",
    "#             shutil.copy(json_source_path, json_destination_path)\n",
    "#             print(\"copied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a00e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-class-alzheimers\n",
      "\n",
      "Loaded the images of dataset-class-frontotemporal\n",
      "\n",
      "Loaded the images of dataset-class-healthy\n",
      "\n",
      "Class 0: 883 samples\n",
      "Class 1: 533 samples\n",
      "Class 2: 786 samples\n"
     ]
    }
   ],
   "source": [
    "#                        *********** Main code for final data laoding and training Starts here *********\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = \"./Final-dataset\"\n",
    "data_dir_list = ['class-alzheimers', 'class-frontotemporal', 'class-healthy']\n",
    "img_data_list = []\n",
    "labels = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(os.path.join(data_path, dataset))\n",
    "    print('Loaded the images of dataset-{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        if img[-3:] == 'png':\n",
    "            input_img = cv2.imread(os.path.join(data_path, dataset, img))\n",
    "            # Convert the image to grayscale if needed\n",
    "            # input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            labels.append(dataset)\n",
    "            input_img_resize = cv2.resize(input_img, (256, 256))  # update the pixel size (if needed)\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "label = label_encoder.transform(labels)\n",
    "\n",
    "img_data = np.array(img_data_list).astype('float32') / 255\n",
    "\n",
    "# Calculate sample count for each class\n",
    "class_counts = np.bincount(label)\n",
    "\n",
    "# Display the sample count for each class\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Class {i}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6dfe793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1541, 256, 256, 3)\n",
      "Test data shape: (661, 256, 256, 3)\n",
      "Training labels shape: (1541, 3)\n",
      "Test labels shape: (661, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Convert labels to one-hot encoded format\n",
    "num_classes = 3\n",
    "Y = to_categorical(label, num_classes)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data, Y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "# print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "# print(\"Validation labels shape:\", y_val.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e0a4aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 613.0 samples in the training set\n",
      "Class 1: 393.0 samples in the training set\n",
      "Class 2: 535.0 samples in the training set\n",
      "Class 0: 270.0 samples in the test set\n",
      "Class 1: 140.0 samples in the test set\n",
      "Class 2: 251.0 samples in the test set\n"
     ]
    }
   ],
   "source": [
    "train_class_counts = np.sum(y_train, axis=0)\n",
    "test_class_counts = np.sum(y_test, axis=0)\n",
    "# val_class_counts = np.sum(y_val, axis=0)\n",
    "\n",
    "# Display the number of samples from each class in the training set\n",
    "for i, count in enumerate(train_class_counts):\n",
    "    print(f\"Class {i}: {count} samples in the training set\")\n",
    "# for i, count in enumerate(val_class_counts):\n",
    "#     print(f\"Class {i}: {count} samples in the validation set\")\n",
    "# Display the number of samples from each class in the test set\n",
    "for i, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {i}: {count} samples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dabf758c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIjCAYAAAAN/63DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLY0lEQVR4nO3deVRV9f7/8ddBJhU4iApIOZCZimOpV8nMzAGcMq2vmVRo3OyWU1lOtzTNCrUysxyqW+ItG+/VHLoOONJVnDDTDC0NpxSo0INoAsr+/dGPvTpXLY6eA8h+Ptb6rOX+7M/e+71Pq+Or3ed8ts0wDEMAAACARXiVdQEAAABAaSIAAwAAwFIIwAAAALAUAjAAAAAshQAMAAAASyEAAwAAwFIIwAAAALAUAjAAAAAshQAMAAAASyEAA8AfSEpKks1m06FDh8y+O+64Q3fccUeZ1QT3OHTokGw2m5KSksq6FACljAAMoELZs2eP7r33XtWtW1f+/v667rrr1LVrV73xxhseu+bx48c1adIk7dq1q0Tji0N1cfP391dERIRiYmI0a9YsnT59+opr2bx5syZNmqRTp05d8Tncac6cOS4FzN9/LjabTUFBQerYsaO++OKLK67hww8/1MyZM6/4eAAVj80wDKOsiwAAd9i8ebM6deqkOnXqKD4+XuHh4Tp69Ki2bNmigwcP6sCBAy6fMykpSYMHD1ZGRobq1asnSSooKJAk+fr6SpJ27NihNm3aaP78+Ro0aFCJz/n8888rMjJShYWFyszM1IYNG5ScnKw6depo6dKlat68ucv1vvLKKxo9erRTvWWpadOmqlGjhjZs2FCi8TabTV27dtVDDz0kwzB0+PBhzZ07VydOnNCKFSsUExPjcg29evXSN9984/QUX5IMw1B+fr58fHxUqVIll88L4NrlXdYFAIC7vPjii7Lb7dq+fbuCg4Od9mVnZ7vtOsXB92p1795drVu3NrfHjx+vdevWqVevXrrrrruUnp6uypUru+Va15KbbrpJDzzwgLl9zz33KCoqSq+//voVBeDLKX76DsB6mAIBoMI4ePCgmjRpclH4laTQ0FCnbZvNpmHDhmnhwoVq2LCh/P391apVK6WkpPzpdX4/B3jDhg1q06aNJGnw4MHm/7q/0nmld955pyZMmKDDhw/rgw8+MPt3796tQYMG6YYbbpC/v7/Cw8P18MMP65dffjHHTJo0SaNHj5YkRUZGmrUUP/mcP3++7rzzToWGhsrPz09RUVGaO3fuRTXs2LFDMTExqlGjhipXrqzIyEg9/PDDTmOKioo0c+ZMNWnSRP7+/goLC9Ojjz6qkydPmmPq1aunvXv3auPGjWYtVzJ3unHjxqpRo4YOHjzo1L9kyRL17NlTERER8vPzU/369TVlyhRduHDBHHPHHXfoiy++0OHDh80aip+MX24O8Lp169ShQwdVrVpVwcHB6tOnj9LT012uG0D5xRNgABVG3bp1lZqaqm+++UZNmzb90/EbN27UJ598ohEjRsjPz09z5sxRbGystm3bVqLjpd/C2fPPP6+JEydqyJAh6tChgyTp1ltvveL7ePDBB/X3v/9dq1ev1iOPPCJJSk5O1g8//KDBgwcrPDxce/fu1dtvv629e/dqy5Ytstls6tevn7777jt99NFHeu2111SjRg1JUs2aNSVJc+fOVZMmTXTXXXfJ29tby5Yt0+OPP66ioiINHTpU0m9Pyrt166aaNWtq3LhxCg4O1qFDh7Ro0SKnGh999FFzKseIESOUkZGhN998U1999ZU2bdokHx8fzZw5U8OHD1dAQICeeeYZSVJYWJjLn4fD4dDJkydVv359p/6kpCQFBARo1KhRCggI0Lp16zRx4kTl5ubq5ZdfliQ988wzcjgcOnbsmF577TVJUkBAwGWvtWbNGnXv3l033HCDJk2apF9//VVvvPGG2rdvr507d5aLaSUA3MAAgApi9erVRqVKlYxKlSoZ0dHRxpgxY4xVq1YZBQUFF42VZEgyduzYYfYdPnzY8Pf3N/r27Wv2zZ8/35BkZGRkmH0dO3Y0OnbsaG5v377dkGTMnz+/RHUWn3P79u2XHWO3242bb77Z3D579uxFYz766CNDkpGSkmL2vfzyyxfV+0fniImJMW644QZze/HixX9a25dffmlIMhYuXOjUv3Llyov6mzRp4vRZ/RlJRkJCgvHTTz8Z2dnZxo4dO4zY2FhDkvHyyy//6f08+uijRpUqVYxz586ZfT179jTq1q170diMjIyL/rm1bNnSCA0NNX755Rez7+uvvza8vLyMhx56qMT3AaB8YwoEgAqja9euSk1N1V133aWvv/5a06dPV0xMjK677jotXbr0ovHR0dFq1aqVuV2nTh316dNHq1atcvrf6GUhICDAaTWI388FPnfunH7++We1a9dOkrRz584SnfP353A4HPr555/VsWNH/fDDD3I4HJJkTh9Zvny5CgsLL3mezz77THa7XV27dtXPP/9stlatWikgIEDr16936V7/17vvvquaNWsqNDRUrVu31tq1azVmzBiNGjXqsvdz+vRp/fzzz+rQoYPOnj2rffv2uXzdEydOaNeuXRo0aJBCQkLM/ubNm6tr1676z3/+c+U3BaBcIQADqFDatGmjRYsW6eTJk9q2bZvGjx+v06dP695779W3337rNLZBgwYXHX/TTTfp7Nmz+umnn0qr5EvKy8tTYGCguZ2Tk6ORI0cqLCxMlStXVs2aNRUZGSlJZnj9M5s2bVKXLl3Mua01a9bU3//+d6dzdOzYUffcc48mT56sGjVqqE+fPpo/f77y8/PN83z//fdyOBwKDQ1VzZo1nVpeXt5V/+CwT58+Sk5O1hdffKFJkybJZrPp7Nmz8vJy/itr79696tu3r+x2u4KCglSzZk3zx3Ml/Ux+7/Dhw5Kkhg0bXrSvcePG+vnnn3XmzJkruCMA5Q1zgAFUSL6+vmrTpo3atGmjm266SYMHD9Znn32m5557rqxL+1PHjh2Tw+HQjTfeaPb1799fmzdv1ujRo9WyZUsFBASoqKhIsbGxKioq+tNzHjx4UJ07d1ajRo00Y8YM1a5dW76+vvrPf/6j1157zTyHzWbTv/71L23ZskXLli3TqlWr9PDDD+vVV1/Vli1bzOuGhoZq4cKFl7xW8ZzjK3X99derS5cukqQePXqoRo0aGjZsmDp16qR+/fpJkk6dOqWOHTsqKChIzz//vOrXry9/f3/t3LlTY8eOLdFnAsC6CMAAKrzipcZOnDjh1P/9999fNPa7775TlSpVXApxNpvt6gr8H++//74kmUt+nTx5UmvXrtXkyZM1ceJEc9yl6r9cLcuWLVN+fr6WLl2qOnXqmP2Xm67Qrl07tWvXTi+++KI+/PBDxcXF6eOPP9Zf//pX1a9fX2vWrFH79u3/dJk2d3w2jz76qF577TU9++yz6tu3r2w2mzZs2KBffvlFixYt0u23326OzcjIuOIa6tatK0nav3//Rfv27dunGjVqqGrVqld4FwDKE6ZAAKgw1q9fL+MS7/Ypnrv5v/9rOzU11Wn+7NGjR7VkyRJ169bNpRcjFIcid7x9bd26dZoyZYoiIyMVFxcnSWYt/3tvl3q72eVqudQ5HA6H5s+f7zTu5MmTF12nZcuWkmROg+jfv78uXLigKVOmXHT98+fPO127atWqV/25eHt766mnnlJ6erqWLFly2fspKCjQnDlzLjq+atWqJZoSUatWLbVs2VILFixwqvmbb77R6tWr1aNHj6u6DwDlB0+AAVQYw4cP19mzZ9W3b181atRIBQUF2rx5sz755BPVq1dPgwcPdhrftGlTxcTEOC2DJkmTJ0926br169dXcHCw5s2bp8DAQFWtWlVt27Y15+hezooVK7Rv3z6dP39eWVlZWrdunZKTk1W3bl0tXbrUfElDUFCQbr/9dk2fPl2FhYW67rrrtHr16ks+7Sz+Ud8zzzyjAQMGyMfHR71791a3bt3k6+ur3r1769FHH1VeXp7eeecdhYaGOj0ZX7BggebMmaO+ffuqfv36On36tN555x0FBQWZAbBjx4569NFHlZiYqF27dqlbt27y8fHR999/r88++0yvv/667r33XrOeuXPn6oUXXtCNN96o0NBQ3XnnnS59vpI0aNAgTZw4UdOmTdPdd9+tW2+9VdWqVVN8fLxGjBghm82m999//5L/AdSqVSt98sknGjVqlNq0aaOAgAD17t37ktd5+eWX1b17d0VHRyshIcFcBs1ut2vSpEku1w2gnCrLJSgAwJ1WrFhhPPzww0ajRo2MgIAAw9fX17jxxhuN4cOHG1lZWU5jJRlDhw41PvjgA6NBgwaGn5+fcfPNNxvr1693GleSZdAMwzCWLFliREVFGd7e3n+6JFrxOYubr6+vER4ebnTt2tV4/fXXjdzc3IuOOXbsmNG3b18jODjYsNvtxv/93/8Zx48fNyQZzz33nNPYKVOmGNddd53h5eXlVPvSpUuN5s2bG/7+/ka9evWMadOmGe+9957TmJ07dxr333+/UadOHcPPz88IDQ01evXq5bRcXLG3337baNWqlVG5cmUjMDDQaNasmTFmzBjj+PHj5pjMzEyjZ8+eRmBgoCHpT5dEK/7ncimTJk0yJJn/jDZt2mS0a9fOqFy5shEREWEue/f7MYZhGHl5ecbAgQON4OBgQ5K5JNqllkEzDMNYs2aN0b59e6Ny5cpGUFCQ0bt3b+Pbb7/9w7oBXFtshnGJ/1wGgArOZrNp6NChevPNN8u6FABAKWMOMAAAACyFAAwAAABLIQADAADAUlgFAoAl8fMHALAungADAADAUgjAAAAAsBSmQJRQUVGRjh8/rsDAQLe/9hQAAABXzzAMnT59WhEREfLyuvxzXgJwCR0/fly1a9cu6zIAAADwJ44eParrr7/+svvLNACnpKTo5ZdfVlpamk6cOKHFixfr7rvvdhqTnp6usWPHauPGjTp//ryioqL073//W3Xq1JEknTt3Tk899ZQ+/vhj5efnKyYmRnPmzFFYWJh5jiNHjuixxx7T+vXrFRAQoPj4eCUmJsrbu+S3HxgYKOm3DzQoKOjqbx4AAABulZubq9q1a5u57XLKNACfOXNGLVq00MMPP6x+/fpdtP/gwYO67bbblJCQoMmTJysoKEh79+6Vv7+/OebJJ5/UF198oc8++0x2u13Dhg1Tv379tGnTJknShQsX1LNnT4WHh2vz5s06ceKEHnroIfn4+Oill14qca3F0x6CgoIIwAAAAOXYn01XLTevQrbZbBc9AR4wYIB8fHz0/vvvX/IYh8OhmjVr6sMPP9S9994rSdq3b58aN26s1NRUtWvXTitWrFCvXr10/Phx86nwvHnzNHbsWP3000/y9fUtUX25ubmy2+1yOBwEYAAAgHKopHmt3K4CUVRUpC+++EI33XSTYmJiFBoaqrZt2+rzzz83x6SlpamwsFBdunQx+xo1aqQ6deooNTVVkpSamqpmzZo5TYmIiYlRbm6u9u7de9nr5+fnKzc316kBAADg2lduA3B2drby8vI0depUxcbGavXq1erbt6/69eunjRs3SpIyMzPl6+ur4OBgp2PDwsKUmZlpjvl9+C3eX7zvchITE2W3283GD+AAAAAqhnIbgIuKiiRJffr00ZNPPqmWLVtq3Lhx6tWrl+bNm+fx648fP14Oh8NsR48e9fg1AQAA4HnlNgDXqFFD3t7eioqKcupv3Lixjhw5IkkKDw9XQUGBTp065TQmKytL4eHh5pisrKyL9hfvuxw/Pz/zB2/88A0AAKDiKLcB2NfXV23atNH+/fud+r/77jvVrVtXktSqVSv5+Pho7dq15v79+/fryJEjio6OliRFR0drz549ys7ONsckJycrKCjoonANAACAiq9Ml0HLy8vTgQMHzO2MjAzt2rVLISEhqlOnjkaPHq377rtPt99+uzp16qSVK1dq2bJl2rBhgyTJbrcrISFBo0aNUkhIiIKCgjR8+HBFR0erXbt2kqRu3bopKipKDz74oKZPn67MzEw9++yzGjp0qPz8/MritgEAAFCGynQZtA0bNqhTp04X9cfHxyspKUmS9N577ykxMVHHjh1Tw4YNNXnyZPXp08ccW/wijI8++sjpRRi/n95w+PBhPfbYY9qwYYOqVq2q+Ph4TZ061aUXYbAMGgAAQPlW0rxWbtYBLu8IwAAAAOXbNb8OMAAAAOAJBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYindZF4DLs9nKugIAnsbL6AGg9PEEGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKWUagFNSUtS7d29FRETIZrPp888/v+zYv/3tb7LZbJo5c6ZTf05OjuLi4hQUFKTg4GAlJCQoLy/Paczu3bvVoUMH+fv7q3bt2po+fboH7gYAAADXgjINwGfOnFGLFi00e/bsPxy3ePFibdmyRRERERfti4uL0969e5WcnKzly5crJSVFQ4YMMffn5uaqW7duqlu3rtLS0vTyyy9r0qRJevvtt91+PwAAACj/vMvy4t27d1f37t3/cMyPP/6o4cOHa9WqVerZs6fTvvT0dK1cuVLbt29X69atJUlvvPGGevTooVdeeUURERFauHChCgoK9N5778nX11dNmjTRrl27NGPGDKegDAAAAGso13OAi4qK9OCDD2r06NFq0qTJRftTU1MVHBxshl9J6tKli7y8vLR161ZzzO233y5fX19zTExMjPbv36+TJ09e9tr5+fnKzc11agAAALj2lesAPG3aNHl7e2vEiBGX3J+ZmanQ0FCnPm9vb4WEhCgzM9McExYW5jSmeLt4zKUkJibKbrebrXbt2ldzKwAAACgnym0ATktL0+uvv66kpCTZbLZSv/748ePlcDjMdvTo0VKvAQAAAO5XbgPwl19+qezsbNWpU0fe3t7y9vbW4cOH9dRTT6levXqSpPDwcGVnZzsdd/78eeXk5Cg8PNwck5WV5TSmeLt4zKX4+fkpKCjIqQEAAODaV24D8IMPPqjdu3dr165dZouIiNDo0aO1atUqSVJ0dLROnTqltLQ087h169apqKhIbdu2NcekpKSosLDQHJOcnKyGDRuqWrVqpXtTAAAAKHNlugpEXl6eDhw4YG5nZGRo165dCgkJUZ06dVS9enWn8T4+PgoPD1fDhg0lSY0bN1ZsbKweeeQRzZs3T4WFhRo2bJgGDBhgLpk2cOBATZ48WQkJCRo7dqy++eYbvf7663rttddK70YBAABQbpRpAN6xY4c6depkbo8aNUqSFB8fr6SkpBKdY+HChRo2bJg6d+4sLy8v3XPPPZo1a5a53263a/Xq1Ro6dKhatWqlGjVqaOLEiSyBBgAAYFE2wzCMsi7iWpCbmyu73S6Hw1Fq84HL4Ld/AEoZ38AA4D4lzWvldg4wAAAA4AkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFhKmQbglJQU9e7dWxEREbLZbPr888/NfYWFhRo7dqyaNWumqlWrKiIiQg899JCOHz/udI6cnBzFxcUpKChIwcHBSkhIUF5entOY3bt3q0OHDvL391ft2rU1ffr00rg9AAAAlENlGoDPnDmjFi1aaPbs2RftO3v2rHbu3KkJEyZo586dWrRokfbv36+77rrLaVxcXJz27t2r5ORkLV++XCkpKRoyZIi5Pzc3V926dVPdunWVlpaml19+WZMmTdLbb7/t8fsDAABA+WMzDMMo6yIkyWazafHixbr77rsvO2b79u36y1/+osOHD6tOnTpKT09XVFSUtm/frtatW0uSVq5cqR49eujYsWOKiIjQ3Llz9cwzzygzM1O+vr6SpHHjxunzzz/Xvn37Slxfbm6u7Ha7HA6HgoKCrupeS8pmK5XLAChD5eMbGAAqhpLmtWtqDrDD4ZDNZlNwcLAkKTU1VcHBwWb4laQuXbrIy8tLW7duNcfcfvvtZviVpJiYGO3fv18nT5687LXy8/OVm5vr1AAAAHDtu2YC8Llz5zR27Fjdf//9ZqLPzMxUaGio0zhvb2+FhIQoMzPTHBMWFuY0pni7eMylJCYmym63m6127druvB0AAACUkWsiABcWFqp///4yDENz584tlWuOHz9eDofDbEePHi2V6wIAAMCzvMu6gD9THH4PHz6sdevWOc3nCA8PV3Z2ttP48+fPKycnR+Hh4eaYrKwspzHF28VjLsXPz09+fn7uug0AAACUE+X6CXBx+P3++++1Zs0aVa9e3Wl/dHS0Tp06pbS0NLNv3bp1KioqUtu2bc0xKSkpKiwsNMckJyerYcOGqlatWuncCAAAAMqNMg3AeXl52rVrl3bt2iVJysjI0K5du3TkyBEVFhbq3nvv1Y4dO7Rw4UJduHBBmZmZyszMVEFBgSSpcePGio2N1SOPPKJt27Zp06ZNGjZsmAYMGKCIiAhJ0sCBA+Xr66uEhATt3btXn3zyiV5//XWNGjWqrG4bAAAAZahMl0HbsGGDOnXqdFF/fHy8Jk2apMjIyEset379et1xxx2SfnsRxrBhw7Rs2TJ5eXnpnnvu0axZsxQQEGCO3717t4YOHart27erRo0aGj58uMaOHetSrSyDBsATWAYNANynpHmt3KwDXN4RgAF4At/AAOA+FXIdYAAAAOBqEYABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKS4H4KNHj+rYsWPm9rZt2/TEE0/o7bffdmthAAAAgCe4HIAHDhyo9evXS5IyMzPVtWtXbdu2Tc8884yef/55txcIAAAAuJPLAfibb77RX/7yF0nSp59+qqZNm2rz5s1auHChkpKS3F0fAAAA4FYuB+DCwkL5+flJktasWaO77rpLktSoUSOdOHHCvdUBAAAAbuZyAG7SpInmzZunL7/8UsnJyYqNjZUkHT9+XNWrV3d7gQAAAIA7uRyAp02bprfeekt33HGH7r//frVo0UKStHTpUnNqBAAAAFBe2QzDMFw96MKFC8rNzVW1atXMvkOHDqlKlSoKDQ11a4HlRW5urux2uxwOh4KCgkrlmjZbqVwGQBly/RsYAHA5Jc1rV7QOsGEYSktL01tvvaXTp09Lknx9fVWlSpUrqxYAAAAoJS4H4MOHD6tZs2bq06ePhg4dqp9++knSb1Mjnn76aZfOlZKSot69eysiIkI2m02ff/65037DMDRx4kTVqlVLlStXVpcuXfT99987jcnJyVFcXJyCgoIUHByshIQE5eXlOY3ZvXu3OnToIH9/f9WuXVvTp0939bYBAABQQbgcgEeOHKnWrVvr5MmTqly5stnft29frV271qVznTlzRi1atNDs2bMvuX/69OmaNWuW5s2bp61bt6pq1aqKiYnRuXPnzDFxcXHau3evkpOTtXz5cqWkpGjIkCHm/tzcXHXr1k1169ZVWlqaXn75ZU2aNIkXdwAAAFiV4aKQkBBj3759hmEYRkBAgHHw4EHDMAwjIyPDqFy5squnM0kyFi9ebG4XFRUZ4eHhxssvv2z2nTp1yvDz8zM++ugjwzAM49tvvzUkGdu3bzfHrFixwrDZbMaPP/5oGIZhzJkzx6hWrZqRn59vjhk7dqzRsGFDl+pzOByGJMPhcFzJ7V2R32YH0mi0itwAAO5T0rzm8hPgoqIiXbhw4aL+Y8eOKTAw8KoDebGMjAxlZmaqS5cuZp/dblfbtm2VmpoqSUpNTVVwcLBat25tjunSpYu8vLy0detWc8ztt98uX19fc0xMTIz279+vkydPXvb6+fn5ys3NdWoAAAC49rkcgLt166aZM2ea2zabTXl5eXruuefUo0cPtxWWmZkpSQoLC3PqDwsLM/dlZmZetOqEt7e3QkJCnMZc6hy/v8alJCYmym63m6127dpXd0MAAAAoF1wOwK+++qo2bdqkqKgonTt3TgMHDlS9evX0448/atq0aZ6osUyMHz9eDofDbEePHi3rkgAAAOAG3q4ecP311+vrr7/Wxx9/rN27dysvL08JCQmKi4tz+lHc1QoPD5ckZWVlqVatWmZ/VlaWWrZsaY7Jzs52Ou78+fPKyckxjw8PD1dWVpbTmOLt4jGX4ufnZ77yGQAAABWHywFY+m2awQMPPODuWpxERkYqPDxca9euNQNvbm6utm7dqscee0ySFB0drVOnTiktLU2tWrWSJK1bt05FRUVq27atOeaZZ55RYWGhfHx8JEnJyclq2LCh04s8AAAAYA0lCsBLly4t8QnvuuuuEo/Ny8vTgQMHzO2MjAzt2rVLISEhqlOnjp544gm98MILatCggSIjIzVhwgRFRETo7rvvliQ1btxYsbGxeuSRRzRv3jwVFhZq2LBhGjBggCIiIiRJAwcO1OTJk5WQkKCxY8fqm2++0euvv67XXnutxHUCAACgAinJkhI2m61EzcvLy6WlKtavX29IuqjFx8cbhvHbUmgTJkwwwsLCDD8/P6Nz587G/v37nc7xyy+/GPfff78REBBgBAUFGYMHDzZOnz7tNObrr782brvtNsPPz8+47rrrjKlTp7pUp2GwDBqNRvNMAwC4T0nzms0wDKMM8/c1o6TvlnYnm61ULgOgDPENDADuU9K85vIqEAAAAMC17IoC8Nq1a9WrVy/Vr19f9evXV69evbRmzRp31wYAAAC4ncsBeM6cOYqNjVVgYKBGjhypkSNHKigoSD169NDs2bM9USMAAADgNi7PAb7++us1btw4DRs2zKl/9uzZeumll/Tjjz+6tcDygjnAADyBOcAA4D4emwN86tQpxcbGXtTfrVs3ORwOV08HAAAAlCqXA/Bdd92lxYsXX9S/ZMkS9erVyy1FAQAAAJ7i8pvgoqKi9OKLL2rDhg2Kjo6WJG3ZskWbNm3SU089pVmzZpljR4wY4b5KAQAAADdweQ5wZGRkyU5ss+mHH364oqLKI+YAA/AE5gADgPuUNK+5/AQ4IyPjqgoDAAAAyhIvwgAAAICluPwE2DAM/etf/9L69euVnZ2toqIip/2LFi1yW3EAAACAu7kcgJ944gm99dZb6tSpk8LCwmRjoioAAACuIS4H4Pfff1+LFi1Sjx49PFEPAAAA4FEuzwG22+264YYbPFELAAAA4HEuB+BJkyZp8uTJ+vXXXz1RDwAAAOBRLk+B6N+/vz766COFhoaqXr168vHxcdq/c+dOtxUHAAAAuJvLATg+Pl5paWl64IEH+BEcAAAArjkuB+AvvvhCq1at0m233eaJegAAAACPcnkOcO3atUvtVcAAAACAu7kcgF999VWNGTNGhw4d8kA5AAAAgGe5PAXigQce0NmzZ1W/fn1VqVLloh/B5eTkuK04AAAAwN1cDsAzZ870QBkAAABA6biiVSAAAACAa5XLAfj3zp07p4KCAqc+fiAHAACA8szlH8GdOXNGw4YNU2hoqKpWrapq1ao5NQAAAKA8czkAjxkzRuvWrdPcuXPl5+enf/zjH5o8ebIiIiL0z3/+0xM1AgAAAG7j8hSIZcuW6Z///KfuuOMODR48WB06dNCNN96ounXrauHChYqLi/NEnQAAAIBbuPwEOCcnRzfccIOk3+b7Fi97dttttyklJcW91QEAAABu5nIAvuGGG5SRkSFJatSokT799FNJvz0ZDg4OdmtxAAAAgLu5HIAHDx6sr7/+WpI0btw4zZ49W/7+/nryySc1evRotxcIAAAAuJPNMAzjak5w6NAh7dy5UzfeeKOaN2/urrrKndzcXNntdjkcjlJb6s1mK5XLAChDV/cNDAD4vZLmtataB1iS6tWrp3r16l3taQAAAIBSUeIpEKmpqVq+fLlT3z//+U9FRkYqNDRUQ4YMUX5+vtsLBAAAANypxAH4+eef1969e83tPXv2KCEhQV26dNG4ceO0bNkyJSYmeqRIAAAAwF1KHIB37dqlzp07m9sff/yx2rZtq3feeUejRo3SrFmzzBUhAAAAgPKqxAH45MmTCgsLM7c3btyo7t27m9tt2rTR0aNH3VsdAAAA4GYlDsBhYWHm+r8FBQXauXOn2rVrZ+4/ffq0fHx83F8hAAAA4EYlDsA9evTQuHHj9OWXX2r8+PGqUqWKOnToYO7fvXu36tev75EiAQAAAHcp8TJoU6ZMUb9+/dSxY0cFBARowYIF8vX1Nfe/99576tatm0eKBAAAANzF5RdhOBwOBQQEqFKlSk79OTk5CggIcArFFQkvwgDgCbwIAwDcx2MvwrDb7ZfsDwkJcfVUAAAAQKkr8RxgAAAAoCIgAAMAAMBSCMAAAACwlBIF4FtuuUUnT56U9Nsrkc+ePevRogAAAABPKVEATk9P15kzZyRJkydPVl5enkeLAgAAADylRKtAtGzZUoMHD9Ztt90mwzD0yiuvKCAg4JJjJ06c6LbiLly4oEmTJumDDz5QZmamIiIiNGjQID377LOy/f81wgzD0HPPPad33nlHp06dUvv27TV37lw1aNDAPE9OTo6GDx+uZcuWycvLS/fcc49ef/31y94DAAAAKq4SBeCkpCQ999xzWr58uWw2m1asWCFv74sPtdlsbg3A06ZN09y5c7VgwQI1adJEO3bs0ODBg2W32zVixAhJ0vTp0zVr1iwtWLBAkZGRmjBhgmJiYvTtt9/K399fkhQXF6cTJ04oOTlZhYWFGjx4sIYMGaIPP/zQbbUCAADg2uDyizC8vLyUmZmp0NBQT9Vk6tWrl8LCwvTuu++afffcc48qV66sDz74QIZhKCIiQk899ZSefvppSb+9qCMsLExJSUkaMGCA0tPTFRUVpe3bt6t169aSpJUrV6pHjx46duyYIiIiSlQLL8IA4Am8CAMA3Kekec3lVSCKiopKJfxK0q233qq1a9fqu+++kyR9/fXX+u9//6vu3btLkjIyMpSZmakuXbqYx9jtdrVt21apqamSpNTUVAUHB5vhV5K6dOkiLy8vbd269bLXzs/PV25urlMDAADAtc/lN8FJ0sGDBzVz5kylp6dLkqKiojRy5EjVr1/frcWNGzdOubm5atSokSpVqqQLFy7oxRdfVFxcnCQpMzNTkhQWFuZ0XFhYmLnvUk+rvb29FRISYo65lMTERE2ePNmdtwMAAIBywOUnwKtWrVJUVJS2bdum5s2bq3nz5tq6dauaNGmi5ORktxb36aefauHChfrwww+1c+dOLViwQK+88ooWLFjg1utcyvjx4+VwOMx29OhRj18TAAAAnufyE+Bx48bpySef1NSpUy/qHzt2rLp27eq24kaPHq1x48ZpwIABkqRmzZrp8OHDSkxMVHx8vMLDwyVJWVlZqlWrlnlcVlaWWrZsKUkKDw9Xdna203nPnz+vnJwc8/hL8fPzk5+fn9vuBQAAAOWDy0+A09PTlZCQcFH/ww8/rG+//dYtRRU7e/asvLycS6xUqZKKiookSZGRkQoPD9fatWvN/bm5udq6dauio6MlSdHR0Tp16pTS0tLMMevWrVNRUZHatm3r1noBAABQ/rn8BLhmzZratWuX0zq7krRr1y63/ziud+/eevHFF1WnTh01adJEX331lWbMmKGHH35Y0m/Lrj3xxBN64YUX1KBBA3MZtIiICN19992SpMaNGys2NlaPPPKI5s2bp8LCQg0bNkwDBgwo8QoQAAAAqDhcDsCPPPKIhgwZoh9++EG33nqrJGnTpk2aNm2aRo0a5dbi3njjDU2YMEGPP/64srOzFRERoUcffdRpreExY8bozJkzGjJkiE6dOqXbbrtNK1euNNcAlqSFCxdq2LBh6ty5s/kijFmzZrm1VgAAAFwbXF4H2DAMzZw5U6+++qqOHz8uSYqIiNDo0aM1YsQI8w1tFQ3rAAPwBNYBBgD3KWleczkA/97p06clSYGBgVd6imsGARiAJxCAAcB9SprXrmgd4GJWCL4AAACoWFxeBQIAAAC4lhGAAQAAYCkEYAAAAFiKSwG4sLBQnTt31vfff++pegAAAACPcikA+/j4aPfu3Z6qBQAAAPA4l6dAPPDAA3r33Xc9UQsAAADgcS4vg3b+/Hm99957WrNmjVq1aqWqVas67Z8xY4bbigMAAADczeUA/M033+iWW26RJH333XdO+yrqW+AAAABQcbgcgNevX++JOgAAAIBSccXLoB04cECrVq3Sr7/+Kkm6ijcqAwAAAKXG5QD8yy+/qHPnzrrpppvUo0cPnThxQpKUkJCgp556yu0FAgAAAO7kcgB+8skn5ePjoyNHjqhKlSpm/3333aeVK1e6tTgAAADA3VyeA7x69WqtWrVK119/vVN/gwYNdPjwYbcVBgAAAHiCy0+Az5w54/Tkt1hOTo78/PzcUhQAAADgKS4H4A4dOuif//ynuW2z2VRUVKTp06erU6dObi0OAAAAcDeXp0BMnz5dnTt31o4dO1RQUKAxY8Zo7969ysnJ0aZNmzxRIwAAAOA2Lj8Bbtq0qb777jvddttt6tOnj86cOaN+/frpq6++Uv369T1RIwAAAOA2NoMFfEskNzdXdrtdDodDQUFBpXJNXqwHVHx8AwOA+5Q0r7k8BUKSTp48qXfffVfp6emSpKioKA0ePFghISFXVi0AAABQSlyeApGSkqJ69epp1qxZOnnypE6ePKlZs2YpMjJSKSkpnqgRAAAAcBuXp0A0a9ZM0dHRmjt3ripVqiRJunDhgh5//HFt3rxZe/bs8UihZY0pEAA8gSkQAOA+Jc1rLj8BPnDggJ566ikz/EpSpUqVNGrUKB04cODKqgUAAABKicsB+JZbbjHn/v5eenq6WrRo4ZaiAAAAAE8p0Y/gdu/ebf55xIgRGjlypA4cOKB27dpJkrZs2aLZs2dr6tSpnqkSAAAAcJMSzQH28vKSzWbTnw212Wy6cOGC24orT5gDDMATmAMMAO7j1mXQMjIy3FYYAAAAUJZKFIDr1q3r6ToAAACAUnFFL8I4fvy4/vvf/yo7O1tFRUVO+0aMGOGWwgAAAABPcDkAJyUl6dFHH5Wvr6+qV68u2+8mqtpsNgIwAAAAyjWXA/CECRM0ceJEjR8/Xl5eLq+iBgAAAJQplxPs2bNnNWDAAMIvAAAArkkuPwFOSEjQZ599pnHjxnmiHgCAVbDWI1DxldO1Hku0DvDvXbhwQb169dKvv/6qZs2aycfHx2n/jBkz3FpgecE6wAA8oZz+3VA6+JIDKr5S/pJz6zrAv5eYmKhVq1apYcOGknTRj+AAAACA8szlAPzqq6/qvffe06BBgzxQDgAAAOBZLv+Szc/PT+3bt/dELQAAAIDHuRyAR44cqTfeeMMTtQAAAAAe5/IUiG3btmndunVavny5mjRpctGP4BYtWuS24gAAAAB3czkABwcHq1+/fp6oBQAAAPA4lwPw/PnzPVEHAAAAUCp4nRsAAAAsxeUnwJGRkX+43u8PP/xwVQUBAAAAnuRyAH7iiSectgsLC/XVV19p5cqVGj16tLvqAgAAADzC5QA8cuTIS/bPnj1bO3bsuOqCAAAAAE9y2xzg7t2769///re7TgcAAAB4hNsC8L/+9S+FhIS463SmH3/8UQ888ICqV6+uypUrq1mzZk5Pmg3D0MSJE1WrVi1VrlxZXbp00ffff+90jpycHMXFxSkoKEjBwcFKSEhQXl6e22sFAABA+efyFIibb77Z6UdwhmEoMzNTP/30k+bMmePW4k6ePKn27durU6dOWrFihWrWrKnvv/9e1apVM8dMnz5ds2bN0oIFCxQZGakJEyYoJiZG3377rfz9/SVJcXFxOnHihJKTk1VYWKjBgwdryJAh+vDDD91aLwAAAMo/m2EYhisHTJ482Wnby8tLNWvW1B133KFGjRq5tbhx48Zp06ZN+vLLLy+53zAMRURE6KmnntLTTz8tSXI4HAoLC1NSUpIGDBig9PR0RUVFafv27WrdurUkaeXKlerRo4eOHTumiIiIS547Pz9f+fn55nZubq5q164th8OhoKAgt97n5fzBYhsAKgjXvoErGL7kgIqvlL/kcnNzZbfb/zSvufwE+LnnnruqwlyxdOlSxcTE6P/+7/+0ceNGXXfddXr88cf1yCOPSJIyMjKUmZmpLl26mMfY7Xa1bdtWqampGjBggFJTUxUcHGyGX0nq0qWLvLy8tHXrVvXt2/eS105MTLwo7AMAAODaV65fhPHDDz9o7ty5atCggVatWqXHHntMI0aM0IIFCyRJmZmZkqSwsDCn48LCwsx9mZmZCg0Nddrv7e2tkJAQc8yljB8/Xg6Hw2xHjx51560BAACgjJT4CbCXl9cfvgBDkmw2m86fP3/VRRUrKipS69at9dJLL0n6bf7xN998o3nz5ik+Pt5t17kUPz8/+fn5efQaAAAAKH0lDsCLFy++7L7U1FTNmjVLRUVFbimqWK1atRQVFeXU17hxY3O5tfDwcElSVlaWatWqZY7JyspSy5YtzTHZ2dlO5zh//rxycnLM4wEAAGAdJQ7Affr0uahv//79GjdunJYtW6a4uDg9//zzbi2uffv22r9/v1Pfd999p7p160r67bXM4eHhWrt2rRl4c3NztXXrVj322GOSpOjoaJ06dUppaWlq1aqVJGndunUqKipS27Zt3VovAAAArgHGFfjxxx+Nv/71r4aPj4/Rq1cvY8+ePVdymj+1bds2w9vb23jxxReN77//3li4cKFRpUoV44MPPjDHTJ061QgODjaWLFli7N692+jTp48RGRlp/Prrr+aY2NhY4+abbza2bt1q/Pe//zUaNGhg3H///S7V4nA4DEmGw+Fw2/39md9+Okmj0Spys7Sy/vBpNJrnWykraV5zqbJTp04ZY8aMMSpXrmxER0cbKSkpV1VkSSxbtsxo2rSp4efnZzRq1Mh4++23nfYXFRUZEyZMMMLCwgw/Pz+jc+fOxv79+53G/PLLL8b9999vBAQEGEFBQcbgwYON06dPu1QHAZhGo3miWVpZf/g0Gs3zrZSVNK+VeB3g6dOna9q0aQoPD9dLL710ySkRFVlJ15VzJ5bIBCq+kn0DV1B8yQEVXyl/yZU0r5U4AHt5eZmvGq5UqdJlxy1atMj1aq8BBGAAnkAABlChldMAXOIfwT300EN/ugwaAAAAUN6VOAAnJSV5sAwAAACgdJTrN8EBAAAA7kYABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGAp11QAnjp1qmw2m5544gmz79y5cxo6dKiqV6+ugIAA3XPPPcrKynI67siRI+rZs6eqVKmi0NBQjR49WufPny/l6gEAAFAeXDMBePv27XrrrbfUvHlzp/4nn3xSy5Yt02effaaNGzfq+PHj6tevn7n/woUL6tmzpwoKCrR582YtWLBASUlJmjhxYmnfAgAAAMqBayIA5+XlKS4uTu+8846qVatm9jscDr377ruaMWOG7rzzTrVq1Urz58/X5s2btWXLFknS6tWr9e233+qDDz5Qy5Yt1b17d02ZMkWzZ89WQUFBWd0SAAAAysg1EYCHDh2qnj17qkuXLk79aWlpKiwsdOpv1KiR6tSpo9TUVElSamqqmjVrprCwMHNMTEyMcnNztXfv3steMz8/X7m5uU4NAAAA1z7vsi7gz3z88cfauXOntm/fftG+zMxM+fr6Kjg42Kk/LCxMmZmZ5pjfh9/i/cX7LicxMVGTJ0++yuoBAABQ3pTrJ8BHjx7VyJEjtXDhQvn7+5fqtcePHy+Hw2G2o0ePlur1AQAA4BnlOgCnpaUpOztbt9xyi7y9veXt7a2NGzdq1qxZ8vb2VlhYmAoKCnTq1Cmn47KyshQeHi5JCg8Pv2hViOLt4jGX4ufnp6CgIKcGAACAa1+5DsCdO3fWnj17tGvXLrO1bt1acXFx5p99fHy0du1a85j9+/fryJEjio6OliRFR0drz549ys7ONsckJycrKChIUVFRpX5PAAAAKFvleg5wYGCgmjZt6tRXtWpVVa9e3exPSEjQqFGjFBISoqCgIA0fPlzR0dFq166dJKlbt26KiorSgw8+qOnTpyszM1PPPvushg4dKj8/v1K/JwAAAJStch2AS+K1116Tl5eX7rnnHuXn5ysmJkZz5swx91eqVEnLly/XY489pujoaFWtWlXx8fF6/vnny7BqAAAAlBWbYRhGWRdxLcjNzZXdbpfD4Si1+cA2W6lcBkAZsvQ3MF9yQMVXyl9yJc1r5XoOMAAAAOBuBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYCgEYAAAAlkIABgAAgKUQgAEAAGApBGAAAABYSrkPwImJiWrTpo0CAwMVGhqqu+++W/v373cac+7cOQ0dOlTVq1dXQECA7rnnHmVlZTmNOXLkiHr27KkqVaooNDRUo0eP1vnz50vzVgAAAFAOlPsAvHHjRg0dOlRbtmxRcnKyCgsL1a1bN505c8Yc8+STT2rZsmX67LPPtHHjRh0/flz9+vUz91+4cEE9e/ZUQUGBNm/erAULFigpKUkTJ04si1sCAABAGbIZhmGUdRGu+OmnnxQaGqqNGzfq9ttvl8PhUM2aNfXhhx/q3nvvlSTt27dPjRs3Vmpqqtq1a6cVK1aoV69eOn78uMLCwiRJ8+bN09ixY/XTTz/J19f3T6+bm5sru90uh8OhoKAgj95jMZutVC4DoAxdW9/AbsaXHFDxlfKXXEnzWrl/Avy/HA6HJCkkJESSlJaWpsLCQnXp0sUc06hRI9WpU0epqamSpNTUVDVr1swMv5IUExOj3Nxc7d2795LXyc/PV25urlMDAADAte+aCsBFRUV64okn1L59ezVt2lSSlJmZKV9fXwUHBzuNDQsLU2Zmpjnm9+G3eH/xvktJTEyU3W43W+3atd18NwAAACgL11QAHjp0qL755ht9/PHHHr/W+PHj5XA4zHb06FGPXxMAAACe513WBZTUsGHDtHz5cqWkpOj66683+8PDw1VQUKBTp045PQXOyspSeHi4OWbbtm1O5yteJaJ4zP/y8/OTn5+fm+8CAAAAZa3cPwE2DEPDhg3T4sWLtW7dOkVGRjrtb9WqlXx8fLR27Vqzb//+/Tpy5Iiio6MlSdHR0dqzZ4+ys7PNMcnJyQoKClJUVFTp3AgAAADKhXL/BHjo0KH68MMPtWTJEgUGBppzdu12uypXriy73a6EhASNGjVKISEhCgoK0vDhwxUdHa127dpJkrp166aoqCg9+OCDmj59ujIzM/Xss89q6NChPOUFAACwmHK/DJrtMsvkzJ8/X4MGDZL024swnnrqKX300UfKz89XTEyM5syZ4zS94fDhw3rssce0YcMGVa1aVfHx8Zo6daq8vUv23wAsgwbAE8r3N7CH8SUHVHzldBm0ch+AywsCMABPsPQ3MF9yQMVXTgNwuZ8DDAAAALgTARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWYqkAPHv2bNWrV0/+/v5q27attm3bVtYlAQAAoJRZJgB/8sknGjVqlJ577jnt3LlTLVq0UExMjLKzs8u6NAAAAJQiywTgGTNm6JFHHtHgwYMVFRWlefPmqUqVKnrvvffKujQAAACUIu+yLqA0FBQUKC0tTePHjzf7vLy81KVLF6Wmpl7ymPz8fOXn55vbDodDkpSbm+vZYgFYCl8pACq0Uv6SK85phmH84ThLBOCff/5ZFy5cUFhYmFN/WFiY9u3bd8ljEhMTNXny5Iv6a9eu7ZEaAViT3V7WFQCAB5XRl9zp06dl/4NrWyIAX4nx48dr1KhR5nZRUZFycnJUvXp12Wy2MqwMFVVubq5q166to0ePKigoqKzLAQC34jsOpcEwDJ0+fVoRERF/OM4SAbhGjRqqVKmSsrKynPqzsrIUHh5+yWP8/Pzk5+fn1BccHOypEgFTUFAQfzkAqLD4joOn/dGT32KW+BGcr6+vWrVqpbVr15p9RUVFWrt2raKjo8uwMgAAAJQ2SzwBlqRRo0YpPj5erVu31l/+8hfNnDlTZ86c0eDBg8u6NAAAAJQiywTg++67Tz/99JMmTpyozMxMtWzZUitXrrzoh3FAWfHz89Nzzz130dQbAKgI+I5DeWIz/mydCAAAAKACscQcYAAAAKAYARgAAACWQgAGAACApRCAgTJQr149zZw5s8TjN2zYIJvNplOnTnmsJgAArIIADPwBm832h23SpElXdN7t27dryJAhJR5/66236sSJEyVa3BsAPM1T343F5/7888/dVitwKZZZBg24EidOnDD//Mknn2jixInav3+/2RcQEGD+2TAMXbhwQd7ef/6vVc2aNV2qw9fX97JvLQSA0ubKdyNQHvEEGPgD4eHhZrPb7bLZbOb2vn37FBgYqBUrVqhVq1by8/PTf//7Xx08eFB9+vRRWFiYAgIC1KZNG61Zs8bpvP87BcJms+kf//iH+vbtqypVqqhBgwZaunSpuf9/p0AkJSUpODhYq1atUuPGjRUQEKDY2Finv5TOnz+vESNGKDg4WNWrV9fYsWMVHx+vu+++25MfGQAL+KPvxvDwcH388cdq3Lix/P391ahRI82ZM8c8tqCgQMOGDVOtWrXk7++vunXrKjExUdJv342S1LdvX9lsNnMbcDcCMHCVxo0bp6lTpyo9PV3NmzdXXl6eevToobVr1+qrr75SbGysevfurSNHjvzheSZPnqz+/ftr9+7d6tGjh+Li4pSTk3PZ8WfPntUrr7yi999/XykpKTpy5Iiefvppc/+0adO0cOFCzZ8/X5s2bVJubi7/WxGAxy1cuFATJ07Uiy++qPT0dL300kuaMGGCFixYIEmaNWuWli5dqk8//VT79+/XwoULzaC7fft2SdL8+fN14sQJcxtwN6ZAAFfp+eefV9euXc3tkJAQtWjRwtyeMmWKFi9erKVLl2rYsGGXPc+gQYN0//33S5JeeuklzZo1S9u2bVNsbOwlxxcWFmrevHmqX7++JGnYsGF6/vnnzf1vvPGGxo8fr759+0qS3nzzTf3nP/+58hsFgBJ47rnn9Oqrr6pfv36SpMjISH377bd66623FB8fryNHjqhBgwa67bbbZLPZVLduXfPY4ulhwcHBTPuCR/EEGLhKrVu3dtrOy8vT008/rcaNGys4OFgBAQFKT0//0yfAzZs3N/9ctWpVBQUFKTs7+7Ljq1SpYoZfSapVq5Y53uFwKCsrS3/5y1/M/ZUqVVKrVq1cujcAcMWZM2d08OBBJSQkKCAgwGwvvPCCDh48KOm3/9jftWuXGjZsqBEjRmj16tVlXDWsiCfAwFWqWrWq0/bTTz+t5ORkvfLKK7rxxhtVuXJl3XvvvSooKPjD8/j4+Dht22w2FRUVuTSeN5sDKEt5eXmSpHfeeUdt27Z12lepUiVJ0i233KKMjAytWLFCa9asUf/+/dWlSxf961//KvV6YV0EYMDNNm3apEGDBplTD/Ly8nTo0KFSrcFutyssLEzbt2/X7bffLkm6cOGCdu7cqZYtW5ZqLQCsIywsTBEREfrhhx8UFxd32XFBQUG67777dN999+nee+9VbGyscnJyFBISIh8fH124cKEUq4YVEYABN2vQoIEWLVqk3r17y2azacKECX/4JNdThg8frsTERN14441q1KiR3njjDZ08eVI2m63UawFgHZMnT9aIESNkt9sVGxur/Px87dixQydPntSoUaM0Y8YM1apVSzfffLO8vLz02WefKTw8XMHBwZJ+Wwli7dq1at++vfz8/FStWrWyvSFUSMwBBtxsxowZqlatmm699Vb17t1bMTExuuWWW0q9jrFjx+r+++/XQw89pOjoaAUEBCgmJkb+/v6lXgsA6/jrX/+qf/zjH5o/f76aNWumjh07KikpSZGRkZKkwMBATZ8+Xa1bt1abNm106NAh/ec//5GX12+R5NVXX1VycrJq166tm2++uSxvBRWYzWDSIGAJRUVFaty4sfr3768pU6aUdTkAAJQZpkAAFdThw4e1evVqdezYUfn5+XrzzTeVkZGhgQMHlnVpAACUKaZAABWUl5eXkpKS1KZNG7Vv31579uzRmjVr1Lhx47IuDQCAMsUUCAAAAFgKT4ABAABgKQRgAAAAWAoBGAAAAJZCAAYAAIClEIABAABgKQRgAAAAWAoBGADKoUGDBslms8lms8nHx0dhYWHq2rWr3nvvPRUVFZX4PElJSQoODvZcoZcxaNAg3X333aV+XQAoCQIwAJRTsbGxOnHihA4dOqQVK1aoU6dOGjlypHr16qXz58+XdXkAcM0iAANAOeXn56fw8HBdd911uuWWW/T3v/9dS5Ys0YoVK5SUlCRJmjFjhpo1a6aqVauqdu3aevzxx5WXlydJ2rBhgwYPHiyHw2E+TZ40aZIk6f3331fr1q0VGBio8PBwDRw4UNnZ2ea1T548qbi4ONWsWVOVK1dWgwYNNH/+fHP/0aNH1b9/fwUHByskJER9+vTRoUOHJEmTJk3SggULtGTJEvO6GzZsKI2PDABKhAAMANeQO++8Uy1atNCiRYsk/fbK61mzZmnv3r1asGCB1q1bpzFjxkiSbr31Vs2cOVNBQUE6ceKETpw4oaefflqSVFhYqClTpujrr7/W559/rkOHDmnQoEHmdSZMmKBvv/1WK1asUHp6uubOnasaNWqYx8bExCgwMFBffvmlNm3apICAAMXGxqqgoEBPP/20+vfvbz7BPnHihG699dbS/aAA4A94l3UBAADXNGrUSLt375YkPfHEE2Z/vXr19MILL+hvf/ub5syZI19fX9ntdtlsNoWHhzud4+GHHzb/fMMNN2jWrFlq06aN8vLyFBAQoCNHjujmm29W69atzXMX++STT1RUVKR//OMfstlskqT58+crODhYGzZsULdu3VS5cmXl5+dfdF0AKA94AgwA1xjDMMzguWbNGnXu3FnXXXedAgMD9eCDD+qXX37R2bNn//AcaWlp6t27t+rUqaPAwEB17NhRknTkyBFJ0mOPPaaPP/5YLVu21JgxY7R582bz2K+//loHDhxQYGCgAgICFBAQoJCQEJ07d04HDx700F0DgPsQgAHgGpOenq7IyEgdOnRIvXr1UvPmzfXvf/9baWlpmj17tiSpoKDgssefOXNGMTExCgoK0sKFC7V9+3YtXrzY6bju3bvr8OHDevLJJ3X8+HF17tzZnD6Rl5enVq1aadeuXU7tu+++08CBAz189wBw9ZgCAQDXkHXr1mnPnj168sknlZaWpqKiIr366qvy8vrtecann37qNN7X11cXLlxw6tu3b59++eUXTZ06VbVr15Yk7dix46Jr1axZU/Hx8YqPj1eHDh00evRovfLKK7rlllv0ySefKDQ0VEFBQZes81LXBYDygifAAFBO5efnKzMzUz/++KN27typl156SX369FGvXr300EMP6cYbb1RhYaHeeOMN/fDDD3r//fc1b948p3PUq1dPeXl5Wrt2rX7++WedPXtWderUka+vr3nc0qVLNWXKFKfjJk6cqCVLlujAgQPau3evli9frsaNG0uS4uLiVKNGDfXp00dffvmlMjIytGHDBo0YMULHjh0zr7t7927t379fP//8swoLC0vnQwOAEiAAA0A5tXLlStWqVUv16tVTbGys1q9fr1mzZmnJkiWqVKmSWrRooRkzZmjatGlq2rSpFi5cqMTERKdz3Hrrrfrb3/6m++67TzVr1tT06dNVs2ZNJSUl6bPPPlNUVJSmTp2qV155xek4X19fjR8/Xs2bN9ftt9+uSpUq6eOPP5YkValSRSkpKapTp4769eunxo0bKyEhQefOnTOfCD/yyCNq2LChWrdurZo1a2rTpk2l86EBQAnYDMMwyroIAAAAoLTwBBgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCkEYAAAAFgKARgAAACWQgAGAACApRCAAQAAYCn/D4UahivHVVd+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of samples in each dataset\n",
    "train_count = len(X_train)\n",
    "# val_count = len(X_val)\n",
    "test_count = len(X_test)\n",
    "\n",
    "# Plotting the bar chart\n",
    "labels = ['Training', 'Test']\n",
    "counts = [train_count, test_count]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, counts, color=['blue', 'red'])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Split Dataset Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fffd8c83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Training data shape: (1541, 256, 256, 3)\n",
      "Reshaped Test data shape: (661, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 256, 256,3)\n",
    "# X_val = X_val.reshape(-1, 126, 126, 3)\n",
    "X_test = X_test.reshape(-1, 256, 256, 3)\n",
    "\n",
    "print(\"Reshaped Training data shape:\", X_train.shape)\n",
    "# print(\"Reshaped Validation data shape:\", X_val.shape)\n",
    "print(\"Reshaped Test data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed3a8b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 126, 126, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 132, 132, 3)  0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 63, 63, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 63, 63, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 63, 63, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 65, 65, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications\n",
    "base_model = applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape= (126, 126, 3)) #Update input shape\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac7726ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 6, 6, 1024)   18875392    conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 1024)         0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_8 (GlobalM (None, 1024)         0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 1024)   0           global_max_pooling2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1, 1, 128)    131200      reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1, 1, 1024)   132096      dense_40[0][0]                   \n",
      "                                                                 dense_40[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 1, 1024)   0           dense_41[0][0]                   \n",
      "                                                                 dense_41[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 1, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 6, 6, 1024)   0           conv2d_18[0][0]                  \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 6, 6, 1)      65536       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 6, 6, 1024)   0           multiply_16[0][0]                \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 1024)         0           multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1024)         1049600     global_average_pooling2d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 512)          524800      dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 3)            1539        dense_43[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 44,367,875\n",
      "Trainable params: 20,780,163\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape, Dense, GlobalMaxPooling2D, Add, Activation, Permute, multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Multiply  # Import Multiply layer\n",
    "\n",
    "def cbam_attention(inputs, reduction_ratio=32):\n",
    "    # Channel attention\n",
    "    x = inputs\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
    "    channel = x.shape[channel_axis]\n",
    "    shared_layer_one = Dense(channel // reduction_ratio, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu', use_bias=True)\n",
    "    shared_layer_two = Dense(channel, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), use_bias=True)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(x)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(x)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    attention_feature = multiply([x, cbam_feature])\n",
    "\n",
    "    # Spatial attention\n",
    "    kernel_size = 8\n",
    "    spatial_attention = Conv2D(1, (kernel_size, kernel_size), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), padding='same', activation='sigmoid', use_bias=False)(attention_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        spatial_attention = Permute((3, 1, 2))(spatial_attention)\n",
    "\n",
    "    attention_feature = multiply([attention_feature, spatial_attention])\n",
    "    return attention_feature\n",
    "\n",
    "# Load ResNet50 base model\n",
    "base_model = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Set base model layers as non-trainable\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of base model\n",
    "x = base_model.output\n",
    "x = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "c = cbam_attention(x, 8)\n",
    "x = GlobalAveragePooling2D()(c)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Output layer for classification\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9df147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add new layers on top of the model\n",
    "# x = base_model.output\n",
    "# # x = GlobalAveragePooling2D()(x)  # Convert features to vectors\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# # x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# # Example of two additional layers\n",
    "# x = Dropout(0.5)(x)  # Dropout layer to reduce overfitting\n",
    "# # x = Dense(1024, activation='relu')(x)  # Another FC layer\n",
    "# x = Dense(256, activation='relu')(x)  \n",
    "\n",
    "# # Assuming a multi-class classification problem\n",
    "# predictions = Dense(3, activation='softmax')(x)  # New softmax layer for 10 classes\n",
    "\n",
    "# # Define the new model\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Compile the model\n",
    "# # base_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "# #               loss='categorical_crossentropy',\n",
    "# #               metrics=['accuracy'])\n",
    "\n",
    "# # Model summary to see all layers\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "340756c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# sgd = SGD(lr=0.001,decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# # We are going to use accuracy metrics and cross entropy loss as performance parameters\n",
    "# from tensorflow.keras.losses import binary_crossentropy,categorical_crossentropy\n",
    "model.compile(\n",
    "     optimizer = Adam(learning_rate = 0.0001),\n",
    "     loss='categorical_crossentropy',\n",
    "     metrics=['accuracy']\n",
    "    )\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=15,\n",
    "    min_delta=0.001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    './checkpoint1/EPOCH.h5', \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a32b33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1541 samples, validate on 661 samples\n",
      "Epoch 1/100\n",
      "1541/1541 [==============================] - 12s 8ms/sample - loss: 1.6419 - acc: 0.3978 - val_loss: 1.5377 - val_acc: 0.4085\n",
      "Epoch 2/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.5389 - acc: 0.3978 - val_loss: 1.5142 - val_acc: 0.4085\n",
      "Epoch 3/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.5206 - acc: 0.3978 - val_loss: 1.4975 - val_acc: 0.4085\n",
      "Epoch 4/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.5045 - acc: 0.3978 - val_loss: 1.4826 - val_acc: 0.4085\n",
      "Epoch 5/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.4891 - acc: 0.3978 - val_loss: 1.4674 - val_acc: 0.4085\n",
      "Epoch 6/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.4741 - acc: 0.3978 - val_loss: 1.4532 - val_acc: 0.4085\n",
      "Epoch 7/100\n",
      "1541/1541 [==============================] - 4s 3ms/sample - loss: 1.4596 - acc: 0.3978 - val_loss: 1.4389 - val_acc: 0.4085\n",
      "Epoch 8/100\n",
      "1541/1541 [==============================] - 5s 3ms/sample - loss: 1.4456 - acc: 0.3978 - val_loss: 1.4241 - val_acc: 0.4085\n",
      "Epoch 9/100\n",
      "1536/1541 [============================>.] - ETA: 0s - loss: 1.4319 - acc: 0.3978"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m     \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m     \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/keras/engine/training.py:708\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    707\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py:658\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    655\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    656\u001b[0m   val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py:428\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_compile_distribution:\n\u001b[1;32m    423\u001b[0m   \u001b[38;5;66;03m# Since we create a new clone from the original model we need to copy\u001b[39;00m\n\u001b[1;32m    424\u001b[0m   \u001b[38;5;66;03m# the weights back to the original model before we can run validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m   distributed_training_utils\u001b[38;5;241m.\u001b[39m_copy_weights_to_original_model(\n\u001b[1;32m    426\u001b[0m       model, ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN)\n\u001b[0;32m--> 428\u001b[0m val_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_iteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_in_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepared_feed_values_from_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_iterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val_results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    442\u001b[0m   val_results \u001b[38;5;241m=\u001b[39m [val_results]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py:394\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m progbar\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_index, batch_logs)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    396\u001b[0m   batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/keras/backend.py:3475\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3470\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3472\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[1;32m   3473\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 3475\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3476\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[1;32m   3478\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   3479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   3480\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   3481\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py:1470\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1469\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1470\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1474\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "     X_train,\n",
    "     y_train,\n",
    "     epochs=100,\n",
    "     batch_size=32,\n",
    "     validation_data=(X_test, y_test),\n",
    "     callbacks=[checkpoint],\n",
    "     verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c8a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(\n",
    "     optimizer= Adam(learning_rate = 0.001) ,\n",
    "     loss='categorical_crossentropy',\n",
    "     metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d643cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=100,\n",
    "    min_delta=0.0001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_directory = './checkpoints/'\n",
    "\n",
    "# Define the filepath pattern for saving model checkpoints\n",
    "# The placeholders {epoch} and {val_acc} will be replaced by the epoch number and validation accuracy\n",
    "filepath_pattern = checkpoint_directory + 'model_{epoch:02d}_{val_acc:.4f}.keras'\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint_directory =  '/workspace/Saksham/workspace,/Saksham/checkpoints'\n",
    "epoch= 200\n",
    "checkpoint = ModelCheckpoint(\n",
    "   filepath_pattern, \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd6d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_model = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epoch,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  \n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "model.evaluate(X_train, y_train)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loaded_model = load_model('/workspace/Cracked/code/My model/Epoch/modelbest.h5')\n",
    "# Define the class labels\n",
    "class_labels = [\"Class 0- CRACKED\", \"Class 1- NON-CRACKED\"]\n",
    "\n",
    "test_folder = \"/workspace/Cracked/data/unseen data/1\" \n",
    "# Iterate over each image in the test folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  \n",
    "        image_path = os.path.join(test_folder, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (128, 128))  \n",
    "        img = img / 255.0 \n",
    "        img = np.expand_dims(img, axis=0)  \n",
    "        # Make predictions\n",
    "        predictions = loaded_model.predict(img)\n",
    "\n",
    "        # Check the class predictions\n",
    "        class_prediction = np.argmax(predictions)\n",
    "\n",
    "        if class_prediction == 0:\n",
    "            result = \"Class 0\"\n",
    "        else:\n",
    "            result = \"Class 1\"\n",
    "\n",
    "#         print(f\"Image {filename} is classified as {result}\")\n",
    "#         cv2.putText(img, result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#         cv2.imshow('Image Classification', img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642464f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
