{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375eb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Loading the dataset for extracting the spectograms from it \n",
    "# import numpy as np \n",
    "# import pandas as pd \n",
    "# import os\n",
    "\n",
    "# for dirname, _, filenames in os.walk('./dataset-2'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aea53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #                      Code to create epoch data from the dataset\n",
    "# import mne\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Create a directory to store the data if it doesn't exist\n",
    "# output_folder = 'epochs_data'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # Read subject information\n",
    "# subjects_info = pd.read_csv('./dataset-2/participants.tsv', delimiter='\\t')\n",
    "\n",
    "# # Create an empty DataFrame to store epochs information\n",
    "# epochs_info_df = pd.DataFrame(columns=['participant_id', 'epoch_index'])\n",
    "\n",
    "# for i in range(1, 89):\n",
    "#     # Load EEG data\n",
    "#     file_path = f'./dataset-2/sub-{i:03}/eeg/sub-{i:03}_task-eyesclosed_eeg.set'\n",
    "#     raw_data = mne.io.read_raw_eeglab(file_path,preload=True)\n",
    "\n",
    "#     # Extract subject information from subjects_info DataFrame\n",
    "#     subject_info = subjects_info[subjects_info['participant_id'] == f'sub-{i:03}'].iloc[0]\n",
    "\n",
    "#     # Create epochs\n",
    "#     epochs = mne.make_fixed_length_epochs(raw_data, duration=45, proj=True, overlap=15)\n",
    "#     epochs_data = epochs.get_data()\n",
    "\n",
    "#     # Save epochs data\n",
    "#     np.save(os.path.join(output_folder, f'subject_{i}.npy'), epochs_data)\n",
    "    \n",
    "#     n=epochs_data.shape[1]\n",
    "#     row_to_duplicate =subjects_info.iloc[i-1]\n",
    "#     duplicated_rows = pd.DataFrame([row_to_duplicate] * n, columns=subjects_info.columns)\n",
    "#     duplicated_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     # Save the duplicated rows to a file\n",
    "#     duplicated_rows.to_csv(os.path.join(output_folder,(f'epochs_information_sub_{i}.csv')), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cf492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(subject_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b67615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Source folders\n",
    "# epochs_folder = 'epochs_data'  # Folder containing EEG data files\n",
    "# json_folder = 'dataset-2'  # Folder containing JSON files\n",
    "\n",
    "# # Destination folder\n",
    "# destination_folder = 'subject_spectrograms_with_json'  # Folder where organized data will be moved\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# if not os.path.exists(destination_folder):\n",
    "#     os.makedirs(destination_folder)\n",
    "\n",
    "# # Iterate through subjects (assuming subjects are numbered from 1 to 88)\n",
    "# for subject_id in range(1, 89):\n",
    "#     # Construct subject ID string with leading zeros\n",
    "#     subject_id_str = f'sub-{subject_id:03}'\n",
    "\n",
    "#     # Find the EEG file for the subject\n",
    "#     eeg_file = f'subject_{subject_id:03}.npy'\n",
    "#     eeg_source_path = os.path.join(epochs_folder, eeg_file)\n",
    "\n",
    "#     # Find the JSON file for the subject\n",
    "#     json_file = f'subject_{subject_id:03}.json'\n",
    "#     json_source_path = os.path.join(json_folder, subject_id_str, 'eeg', json_file)\n",
    "\n",
    "#     # Create a folder for the subject in the destination folder\n",
    "#     subject_folder = os.path.join(destination_folder, subject_id_str)\n",
    "#     os.makedirs(subject_folder, exist_ok=True)\n",
    "\n",
    "#     # Move the JSON file to the subject folder\n",
    "#     if os.path.exists(json_source_path):\n",
    "#         shutil.copy(json_source_path, subject_folder)\n",
    "\n",
    "#     # Generate spectrogram for the EEG data\n",
    "#     if os.path.exists(eeg_source_path):\n",
    "#         eeg_data = np.load(eeg_source_path)  # Load EEG data\n",
    "#         sampling_rate = 1000  # Sample rate in Hz\n",
    "\n",
    "#         # Assuming EEG data is in the first column of the DataFrame and each row corresponds to an epoch\n",
    "#         for epoch_index in range(len(eeg_data)):\n",
    "#             epoch_eeg_data = eeg_data[epoch_index]\n",
    "#             save_path = os.path.join(destination_folder, f'spectrogram_{subject_id:03}_epoch_{epoch_index}.png')\n",
    "#             plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ff4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Source folders\n",
    "# epochs_folder = 'epochs_data'  # Folder containing EEG data files\n",
    "# json_folder = 'dataset-2'  # Folder containing JSON files\n",
    "\n",
    "# # Destination folder\n",
    "# destination_folder = 'subject_spectrograms_with_json'  # Folder where organized data will be moved\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# if not os.path.exists(destination_folder):\n",
    "#     os.makedirs(destination_folder)\n",
    "\n",
    "# # Iterate through subjects (assuming subjects are numbered from 1 to 88)\n",
    "# for subject_id in range(1, 89):\n",
    "#     # Construct subject ID string with leading zeros\n",
    "#     subject_id_str = f'sub-{subject_id:03}'\n",
    "\n",
    "#     # Find the EEG file for the subject\n",
    "#     eeg_file = f'subject_{subject_id:03}.npy'\n",
    "#     eeg_source_path = os.path.join(epochs_folder, eeg_file)\n",
    "\n",
    "#     # Find the JSON file for the subject\n",
    "#     json_file = f'subject_{subject_id:03}.json'\n",
    "#     json_source_path = os.path.join(json_folder, subject_id_str, 'eeg', json_file)\n",
    "\n",
    "#     # Create a folder for the subject in the destination folder\n",
    "#     subject_folder = os.path.join(destination_folder, subject_id_str)\n",
    "#     os.makedirs(subject_folder, exist_ok=True)\n",
    "    \n",
    "    \n",
    "#     csv_files = [file for file in os.listdir(epochs_folder) if file.endswith('.csv')]\n",
    "#     # Generate spectrogram for the EEG data and move JSON file\n",
    "#     if os.path.exists(eeg_source_path):\n",
    "#         # Load EEG data (assuming it's in the form of a numpy array)\n",
    "#         for csv_file in csv_files:\n",
    "#             csv_path = os.path.join(folder_path, csv_file)\n",
    "#             participant_data = pd.read_csv(csv_path)\n",
    "#             eeg_data = np.load(os.path.join(folder_path, f'subject_{csv_file.split(\"_\")[3].split(\".\")[0]}.npy'))  # Load EEG data (replace with your actual file naming convention)\n",
    "#             sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is in the first column of the DataFrame and each row corresponds to an epoch\n",
    "#             for epoch_index in range(len(eeg_data)):\n",
    "#                 epoch_eeg_data = eeg_data[epoch_index]\n",
    "#                 save_path = os.path.join(spectrogram_folder, f'spectrogram_{csv_file.split(\"_\")[3].split(\".\")[0]}_epoch_{epoch_index}.png')\n",
    "#                 plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "            \n",
    "#     # Move the JSON file to the subject folder\n",
    "#     if os.path.exists(json_source_path):\n",
    "#         shutil.copy(json_source_path, subject_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6362900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #       Code for converting the csv and nmpy files into spectograms in png format \n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis', NFFT=256)\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')a\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Read all CSV files into a single DataFrame\n",
    "# folder_path = 'epochs_data'\n",
    "# csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# # Create a directory to store spectrogram images if it doesn't exist\n",
    "# spectrogram_folder = 'spectrograms'\n",
    "# if not os.path.exists(spectrogram_folder):\n",
    "#     os.makedirs(spectrogram_folder)\n",
    "\n",
    "# for csv_file in csv_files:\n",
    "#     csv_path = os.path.join(folder_path, csv_file)\n",
    "#     participant_data = pd.read_csv(csv_path)\n",
    "#     participant_id = csv_file.split(\"_\")[3].split(\".\")[0]\n",
    "#     participant_folder = os.path.join(spectrogram_folder, f'sub-{participant_id}')\n",
    "#     if not os.path.exists(participant_folder):\n",
    "#         os.makedirs(participant_folder)\n",
    "        \n",
    "#     eeg_data_path = os.path.join(folder_path, f'subject_{participant_id}.npy')  # Assuming EEG data path\n",
    "#     eeg_data = np.load(eeg_data_path)  # Load EEG data\n",
    "#     sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is a 2D array where each row corresponds to an epoch\n",
    "#     for epoch_index, epoch_eeg_data in enumerate(eeg_data):\n",
    "#         save_path = os.path.join(participant_folder, f'spectrogram_epoch_{epoch_index}.png')\n",
    "#         plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6f8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Function to plot spectrogram and save as image\n",
    "# def plot_spectrogram_and_save(eeg_data, sampling_rate, save_path):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.specgram(eeg_data, Fs=sampling_rate, cmap='viridis', NFFT=256)\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.title('Spectrogram')\n",
    "#     plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "#     plt.savefig(save_path)  # Save the spectrogram plot as an image\n",
    "#     plt.close()  # Close the plot to free memory\n",
    "\n",
    "# # Read all CSV files into a single DataFrame\n",
    "# folder_path = 'epochs_data'\n",
    "# csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# # Create a directory to store spectrogram images if it doesn't exist\n",
    "# spectrogram_folder = 'spectrograms'\n",
    "# if not os.path.exists(spectrogram_folder):\n",
    "#     os.makedirs(spectrogram_folder)\n",
    "\n",
    "# for csv_file in csv_files:\n",
    "#     csv_path = os.path.join(folder_path, csv_file)\n",
    "#     participant_data = pd.read_csv(csv_path)\n",
    "#     participant_id = csv_file.split(\"_\")[3].split(\".\")[0]\n",
    "#     participant_folder = os.path.join(spectrogram_folder, f'sub-{participant_id}')\n",
    "#     if not os.path.exists(participant_folder):\n",
    "#         os.makedirs(participant_folder)\n",
    "        \n",
    "#     eeg_data_path = os.path.join(folder_path, f'subject_{participant_id}.npy')  # Assuming EEG data path\n",
    "#     eeg_data = np.load(eeg_data_path)  # Load EEG data\n",
    "#     sampling_rate = 1000  # Sample rate in Hz\n",
    "#     # Assuming EEG data is a 2D array where each row corresponds to an epoch\n",
    "#     for epoch_index, epoch_eeg_data in enumerate(eeg_data):\n",
    "#         save_path = os.path.join(participant_folder, f'spectrogram_epoch_{epoch_index}.png')\n",
    "#         plot_spectrogram_and_save(epoch_eeg_data, sampling_rate, save_path)\n",
    "    \n",
    "#     # Move the JSON file to the participant folder\n",
    "#         json_source_path = os.path.join('dataset-2', f'sub-{participant_id}', 'eeg', f'sub-{participant_id}_task-eyesclosed_channels.tsv')\n",
    "#         json_destination_path = os.path.join(participant_folder, f'subject_{participant_id}.tsv')\n",
    "#         if os.path.exists(json_source_path):\n",
    "#             shutil.copy(json_source_path, json_destination_path)\n",
    "#             print(\"copied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a00e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-class-alzheimers\n",
      "\n",
      "Loaded the images of dataset-class-frontotemporal\n",
      "\n",
      "Loaded the images of dataset-class-healthy\n",
      "\n",
      "Class 0: 883 samples\n",
      "Class 1: 533 samples\n",
      "Class 2: 786 samples\n"
     ]
    }
   ],
   "source": [
    "#                        *********** Main code for final data laoding and training Starts here *********\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = \"./Final-dataset\"\n",
    "data_dir_list = ['class-alzheimers', 'class-frontotemporal', 'class-healthy']\n",
    "img_data_list = []\n",
    "labels = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(os.path.join(data_path, dataset))\n",
    "    print('Loaded the images of dataset-{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        if img[-3:] == 'png':\n",
    "            input_img = cv2.imread(os.path.join(data_path, dataset, img))\n",
    "            # Convert the image to grayscale if needed\n",
    "            # input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            labels.append(dataset)\n",
    "            input_img_resize = cv2.resize(input_img, (256, 256))  # update the pixel size (if needed)\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "label = label_encoder.transform(labels)\n",
    "\n",
    "img_data = np.array(img_data_list).astype('float32') / 255\n",
    "\n",
    "# Calculate sample count for each class\n",
    "class_counts = np.bincount(label)\n",
    "\n",
    "# Display the sample count for each class\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Class {i}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dfe793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1541, 256, 256, 3)\n",
      "Test data shape: (661, 256, 256, 3)\n",
      "Training labels shape: (1541, 3)\n",
      "Test labels shape: (661, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Convert labels to one-hot encoded format\n",
    "num_classes = 3\n",
    "Y = to_categorical(label, num_classes)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data, Y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "# print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "# print(\"Validation labels shape:\", y_val.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0a4aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 613.0 samples in the training set\n",
      "Class 1: 393.0 samples in the training set\n",
      "Class 2: 535.0 samples in the training set\n",
      "Class 0: 270.0 samples in the test set\n",
      "Class 1: 140.0 samples in the test set\n",
      "Class 2: 251.0 samples in the test set\n"
     ]
    }
   ],
   "source": [
    "train_class_counts = np.sum(y_train, axis=0)\n",
    "test_class_counts = np.sum(y_test, axis=0)\n",
    "# val_class_counts = np.sum(y_val, axis=0)\n",
    "\n",
    "# Display the number of samples from each class in the training set\n",
    "for i, count in enumerate(train_class_counts):\n",
    "    print(f\"Class {i}: {count} samples in the training set\")\n",
    "# for i, count in enumerate(val_class_counts):\n",
    "#     print(f\"Class {i}: {count} samples in the validation set\")\n",
    "# Display the number of samples from each class in the test set\n",
    "for i, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {i}: {count} samples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabf758c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of samples in each dataset\n",
    "train_count = len(X_train)\n",
    "# val_count = len(X_val)\n",
    "test_count = len(X_test)\n",
    "\n",
    "# Plotting the bar chart\n",
    "labels = ['Training', 'Test']\n",
    "counts = [train_count, test_count]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, counts, color=['blue', 'red'])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Split Dataset Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fffd8c83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Training data shape: (1541, 256, 256, 3)\n",
      "Reshaped Test data shape: (661, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 256, 256,3)\n",
    "# X_val = X_val.reshape(-1, 126, 126, 3)\n",
    "X_test = X_test.reshape(-1, 256, 256, 3)\n",
    "\n",
    "print(\"Reshaped Training data shape:\", X_train.shape)\n",
    "# print(\"Reshaped Validation data shape:\", X_val.shape)\n",
    "print(\"Reshaped Test data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3a8b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import applications\n",
    "# base_model = applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape= (126, 126, 3)) #Update input shape\n",
    "# base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7726ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,545</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,760</span> │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │     \u001b[38;5;34m73,856\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m512\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │    \u001b[38;5;34m295,168\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m8,224\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m8,448\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_12[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_13[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m256\u001b[0m)              │            │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │     \u001b[38;5;34m12,545\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │     \u001b[38;5;34m73,760\u001b[0m │ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │      \u001b[38;5;34m8,224\u001b[0m │ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m16,896\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">692,292</span> (2.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m692,292\u001b[0m (2.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">691,332</span> (2.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m691,332\u001b[0m (2.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Reshape, Dense, GlobalMaxPooling2D, Add, Activation, Permute, multiply\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras.layers import Multiply  # Import Multiply layer\n",
    "\n",
    "# def cbam_attention(inputs, reduction_ratio=32):\n",
    "#     # Channel attention\n",
    "#     x = inputs\n",
    "#     channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
    "#     channel = x.shape[channel_axis]\n",
    "#     shared_layer_one = Dense(channel // reduction_ratio, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu', use_bias=True)\n",
    "#     shared_layer_two = Dense(channel, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), use_bias=True)\n",
    "\n",
    "#     avg_pool = GlobalAveragePooling2D()(x)\n",
    "#     avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "#     avg_pool = shared_layer_one(avg_pool)\n",
    "#     avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "#     max_pool = GlobalMaxPooling2D()(x)\n",
    "#     max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "#     max_pool = shared_layer_one(max_pool)\n",
    "#     max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "#     cbam_feature = Add()([avg_pool, max_pool])\n",
    "#     cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "#     if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "#         cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "#     attention_feature = multiply([x, cbam_feature])\n",
    "\n",
    "#     # Spatial attention\n",
    "#     kernel_size = 8\n",
    "#     spatial_attention = Conv2D(1, (kernel_size, kernel_size), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), padding='same', activation='sigmoid', use_bias=False)(attention_feature)\n",
    "\n",
    "#     if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "#         spatial_attention = Permute((3, 1, 2))(spatial_attention)\n",
    "\n",
    "#     attention_feature = multiply([attention_feature, spatial_attention])\n",
    "#     return attention_feature\n",
    "\n",
    "# # Load ResNet50 base model\n",
    "# base_model = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# # Set base model layers as non-trainable\n",
    "# base_model.trainable = False\n",
    "\n",
    "# # Add custom layers on top of base model\n",
    "# x = base_model.output\n",
    "# x = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "# c = cbam_attention(x, 8)\n",
    "# x = GlobalAveragePooling2D()(c)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# # Output layer for classification\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# # Create the final model\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Print model summary\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Activation, Multiply, Input, Add, Flatten, GlobalMaxPooling2D, Dense, Reshape, BatchNormalization, GlobalAveragePooling2D, Permute\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def cbam_attention(inputs, reduction_ratio=8):\n",
    "    # Channel attention\n",
    "    x = inputs\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
    "    channel = x.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel // reduction_ratio, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')\n",
    "    shared_layer_two = Dense(channel, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), use_bias=True)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(x)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(x)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "        \n",
    "    attention_feature = Multiply()([x, cbam_feature])\n",
    "\n",
    "    # Spatial attention\n",
    "    kernel_size = 7\n",
    "    spatial_attention = Conv2D(1, (kernel_size, kernel_size), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), padding='same')(attention_feature)\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == \"channels_first\":\n",
    "        spatial_attention = Permute((3, 1, 2))(spatial_attention)\n",
    "\n",
    "    attention_feature = Multiply()([attention_feature, spatial_attention])\n",
    "\n",
    "    return attention_feature\n",
    "\n",
    "def residual_block(input_layer, filters, kernel_size):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # Add a 1x1 convolutional layer to adjust the number of channels\n",
    "    adjust_channels = layers.Conv2D(filters, (1, 1), padding='same')(input_layer)\n",
    "    x = Add()([x, adjust_channels])\n",
    "    return x\n",
    "\n",
    "# Explicitly name the input layer\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "\n",
    "ds_1 = Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(visible)\n",
    "x1 = BatchNormalization()(ds_1)\n",
    "ds_2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x1)\n",
    "x2 = BatchNormalization()(ds_2)\n",
    "ds_3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x2)\n",
    "x3 = BatchNormalization()(ds_3)\n",
    "ds_4 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(x3)\n",
    "x4 = BatchNormalization()(ds_4)\n",
    "# ds_5 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.003), activation='relu')(ds_4)\n",
    "c = cbam_attention(x4, 8)\n",
    "\n",
    "# Residual block 1\n",
    "x = residual_block(c, filters=32, kernel_size=(3, 3))\n",
    "\n",
    "\n",
    "#replace global average pulling \n",
    "# Spatial Pyramid Pooling (SPP)\n",
    "# pool_sizes = [4, 2, 1] \n",
    "# spp_layers = []\n",
    "# for pool_size in pool_sizes:\n",
    "#     spp = layers.MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n",
    "#     spp = layers.Flatten()(spp)\n",
    "#     spp_layers.append(spp)\n",
    "\n",
    "# spp = layers.Concatenate()(spp_layers)\n",
    "# x = layers.Dense(512, activation='relu')(spp)\n",
    "# x1 = layers.Dropout(0.25)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x1 = Dropout(0.25)(x)\n",
    "\n",
    "# Fully Connected Layers\n",
    "x10 = Dense(256, activation='relu')(x1)\n",
    "x10 = Dense(128, activation='relu')(x10)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = Dense(3, activation='softmax')(x10)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=visible, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9df147b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Add new layers on top of the model\n",
    "# x = base_model.output\n",
    "# # x = GlobalAveragePooling2D()(x)  # Convert features to vectors\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# # x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# # Example of two additional layers\n",
    "# x = Dropout(0.5)(x)  # Dropout layer to reduce overfitting\n",
    "# # x = Dense(1024, activation='relu')(x)  # Another FC layer\n",
    "# x = Dense(256, activation='relu')(x)  \n",
    "\n",
    "# # Assuming a multi-class classification problem\n",
    "# predictions = Dense(3, activation='softmax')(x)  # New softmax layer for 10 classes\n",
    "\n",
    "# # Define the new model\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # Compile the model\n",
    "# # base_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "# #               loss='categorical_crossentropy',\n",
    "# #               metrics=['accuracy'])\n",
    "\n",
    "# # Model summary to see all layers\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "340756c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# sgd = SGD(lr=0.001,decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# # We are going to use accuracy metrics and cross entropy loss as performance parameters\n",
    "# from tensorflow.keras.losses import binary_crossentropy,categorical_crossentropy\n",
    "model.compile(\n",
    "     optimizer = Adam(learning_rate = 0.0001),\n",
    "     loss='categorical_crossentropy',\n",
    "     metrics=['accuracy']\n",
    "    )\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=15,\n",
    "    min_delta=0.001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    './checkpoint1/EPOCH.keras', \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a32b33e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 2/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57:59\u001b[0m 74s/step - accuracy: 0.2031 - loss: 12.8204  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m      X_train,\n\u001b[1;32m      3\u001b[0m      y_train,\n\u001b[1;32m      4\u001b[0m      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      5\u001b[0m      batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      6\u001b[0m      validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m      7\u001b[0m      callbacks\u001b[38;5;241m=\u001b[39m[checkpoint],\n\u001b[1;32m      8\u001b[0m      verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    878\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "     X_train,\n",
    "     y_train,\n",
    "     epochs=100,\n",
    "     batch_size=32,\n",
    "     validation_data=(X_test, y_test),\n",
    "     callbacks=[checkpoint],\n",
    "     verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c8a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(\n",
    "     optimizer= Adam(learning_rate = 0.001) ,\n",
    "     loss='categorical_crossentropy',\n",
    "     metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d643cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=100,\n",
    "    min_delta=0.0001,\n",
    "    monitor=\"val_acc\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_directory = './checkpoints/'\n",
    "\n",
    "# Define the filepath pattern for saving model checkpoints\n",
    "# The placeholders {epoch} and {val_acc} will be replaced by the epoch number and validation accuracy\n",
    "filepath_pattern = checkpoint_directory + 'model_{epoch:02d}_{val_acc:.4f}.keras'\n",
    "# Define the ModelCheckpoint callback to save the best weights\n",
    "checkpoint_directory =  '/workspace/Saksham/workspace,/Saksham/checkpoints'\n",
    "epoch= 200\n",
    "checkpoint = ModelCheckpoint(\n",
    "   filepath_pattern, \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd6d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_model = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epoch,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),  \n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "model.evaluate(X_train, y_train)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loaded_model = load_model('/workspace/Cracked/code/My model/Epoch/modelbest.h5')\n",
    "# Define the class labels\n",
    "class_labels = [\"Class 0- CRACKED\", \"Class 1- NON-CRACKED\"]\n",
    "\n",
    "test_folder = \"/workspace/Cracked/data/unseen data/1\" \n",
    "# Iterate over each image in the test folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  \n",
    "        image_path = os.path.join(test_folder, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (128, 128))  \n",
    "        img = img / 255.0 \n",
    "        img = np.expand_dims(img, axis=0)  \n",
    "        # Make predictions\n",
    "        predictions = loaded_model.predict(img)\n",
    "\n",
    "        # Check the class predictions\n",
    "        class_prediction = np.argmax(predictions)\n",
    "\n",
    "        if class_prediction == 0:\n",
    "            result = \"Class 0\"\n",
    "        else:\n",
    "            result = \"Class 1\"\n",
    "\n",
    "#         print(f\"Image {filename} is classified as {result}\")\n",
    "#         cv2.putText(img, result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#         cv2.imshow('Image Classification', img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642464f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
